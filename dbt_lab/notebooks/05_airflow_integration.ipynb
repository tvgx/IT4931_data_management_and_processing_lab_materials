{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 5: Airflow Integration - Orchestrating dbt v·ªõi Airflow\n",
        "\n",
        "## üéØ Objectives\n",
        "- T√≠ch h·ª£p dbt v·ªõi Airflow\n",
        "- S·ª≠ d·ª•ng dbt operators trong Airflow\n",
        "- Schedule dbt runs v·ªõi Airflow\n",
        "- Error handling v√† retries\n",
        "- Best practices cho dbt + Airflow\n",
        "\n",
        "## üìã Prerequisites\n",
        "- Ho√†n th√†nh Lab 1-4\n",
        "- Airflow Lab ƒë√£ ho√†n th√†nh\n",
        "- Airflow cluster ƒëang ch·∫°y\n",
        "- dbt project ƒë√£ setup\n",
        "\n",
        "## üèóÔ∏è Integration Overview\n",
        "\n",
        "**Airflow + dbt** l√† combination m·∫°nh m·∫Ω:\n",
        "- **Airflow**: Orchestration v√† scheduling\n",
        "- **dbt**: Data transformations\n",
        "- **Together**: Complete data pipeline\n",
        "\n",
        "### Architecture:\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   Sources    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Airflow   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     dbt     ‚îÇ\n",
        "‚îÇ  (Raw Data) ‚îÇ     ‚îÇ(Orchestrate) ‚îÇ     ‚îÇ(Transform)  ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                            ‚îÇ\n",
        "                            ‚ñº\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ   Models    ‚îÇ\n",
        "                    ‚îÇ (Analytics) ‚îÇ\n",
        "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. dbt Operators trong Airflow\n",
        "\n",
        "Airflow c√≥ built-in operators cho dbt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîß dbt Operators trong Airflow:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\"\"\n",
        "1. DbtRunOperator\n",
        "   - Ch·∫°y dbt run command\n",
        "   - Usage:\n",
        "     from airflow.providers.dbt.cloud.operators.dbt import DbtRunOperator\n",
        "     \n",
        "     dbt_run = DbtRunOperator(\n",
        "         task_id='dbt_run',\n",
        "         dbt_conn_id='dbt_default',\n",
        "         project_dir='/path/to/dbt/project',\n",
        "         profiles_dir='/path/to/profiles',\n",
        "         select=['staging.*']\n",
        "     )\n",
        "\n",
        "2. DbtTestOperator\n",
        "   - Ch·∫°y dbt test command\n",
        "   - Usage:\n",
        "     from airflow.providers.dbt.cloud.operators.dbt import DbtTestOperator\n",
        "     \n",
        "     dbt_test = DbtTestOperator(\n",
        "         task_id='dbt_test',\n",
        "         dbt_conn_id='dbt_default',\n",
        "         project_dir='/path/to/dbt/project',\n",
        "         profiles_dir='/path/to/profiles'\n",
        "     )\n",
        "\n",
        "3. DbtDocsGenerateOperator\n",
        "   - Generate dbt documentation\n",
        "   - Usage:\n",
        "     from airflow.providers.dbt.cloud.operators.dbt import DbtDocsGenerateOperator\n",
        "     \n",
        "     dbt_docs = DbtDocsGenerateOperator(\n",
        "         task_id='dbt_docs',\n",
        "         dbt_conn_id='dbt_default',\n",
        "         project_dir='/path/to/dbt/project'\n",
        "     )\n",
        "\n",
        "4. BashOperator (Alternative)\n",
        "   - Ch·∫°y dbt commands qua bash\n",
        "   - Usage:\n",
        "     from airflow.operators.bash import BashOperator\n",
        "     \n",
        "     dbt_run = BashOperator(\n",
        "         task_id='dbt_run',\n",
        "         bash_command='cd /path/to/dbt/project && dbt run --profiles-dir .'\n",
        "     )\n",
        "\"\"\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Complete Airflow DAG v·ªõi dbt\n",
        "\n",
        "T·∫°o DAG ho√†n ch·ªânh t√≠ch h·ª£p dbt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example Airflow DAG v·ªõi dbt\n",
        "dag_example = \"\"\"\n",
        "from airflow.sdk import DAG, task\n",
        "from airflow.operators.bash import BashOperator\n",
        "from airflow.providers.standard.operators.empty import EmptyOperator\n",
        "import pendulum\n",
        "\n",
        "@dag(\n",
        "    dag_id='dbt_pipeline',\n",
        "    schedule='@daily',\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz='UTC'),\n",
        "    catchup=False,\n",
        "    tags=['dbt', 'data-pipeline'],\n",
        ")\n",
        "def dbt_pipeline():\n",
        "    start = EmptyOperator(task_id='start')\n",
        "    \n",
        "    # Run staging models\n",
        "    dbt_run_staging = BashOperator(\n",
        "        task_id='dbt_run_staging',\n",
        "        bash_command='cd /path/to/dbt_lab && dbt run --select staging.* --profiles-dir . --project-dir .',\n",
        "    )\n",
        "    \n",
        "    # Run marts models\n",
        "    dbt_run_marts = BashOperator(\n",
        "        task_id='dbt_run_marts',\n",
        "        bash_command='cd /path/to/dbt_lab && dbt run --select marts.* --profiles-dir . --project-dir .',\n",
        "    )\n",
        "    \n",
        "    # Run tests\n",
        "    dbt_test = BashOperator(\n",
        "        task_id='dbt_test',\n",
        "        bash_command='cd /path/to/dbt_lab && dbt test --profiles-dir . --project-dir .',\n",
        "    )\n",
        "    \n",
        "    # Generate docs\n",
        "    dbt_docs = BashOperator(\n",
        "        task_id='dbt_docs',\n",
        "        bash_command='cd /path/to/dbt_lab && dbt docs generate --profiles-dir . --project-dir .',\n",
        "    )\n",
        "    \n",
        "    end = EmptyOperator(task_id='end')\n",
        "    \n",
        "    # Define dependencies\n",
        "    start >> dbt_run_staging >> dbt_run_marts >> dbt_test >> dbt_docs >> end\n",
        "\n",
        "dbt_pipeline_instance = dbt_pipeline()\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìã Complete Airflow DAG Example:\")\n",
        "print(\"=\" * 60)\n",
        "print(dag_example)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüí° Key Points:\")\n",
        "print(\"  - Run staging models tr∆∞·ªõc\")\n",
        "print(\"  - Run marts models sau\")\n",
        "print(\"  - Run tests ƒë·ªÉ verify\")\n",
        "print(\"  - Generate docs cu·ªëi c√πng\")\n",
        "print(\"  - Error handling v·ªõi retries\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Error Handling v√† Retries\n",
        "\n",
        "Best practices cho error handling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üõ°Ô∏è Error Handling Best Practices:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\"\"\n",
        "1. Set retries cho dbt tasks:\n",
        "   dbt_run = BashOperator(\n",
        "       task_id='dbt_run',\n",
        "       bash_command='...',\n",
        "       retries=3,\n",
        "       retry_delay=timedelta(minutes=5),\n",
        "   )\n",
        "\n",
        "2. Use on_failure_callback:\n",
        "   def handle_dbt_failure(context):\n",
        "       # Send alerts, cleanup, etc.\n",
        "       pass\n",
        "   \n",
        "   dbt_run = BashOperator(\n",
        "       task_id='dbt_run',\n",
        "       bash_command='...',\n",
        "       on_failure_callback=handle_dbt_failure,\n",
        "   )\n",
        "\n",
        "3. Check dbt exit codes:\n",
        "   - 0: Success\n",
        "   - 1: General error\n",
        "   - 2: Parse error\n",
        "   \n",
        "   Use check=True trong BashOperator ƒë·ªÉ fail on error\n",
        "\n",
        "4. Store dbt logs:\n",
        "   dbt_run = BashOperator(\n",
        "       task_id='dbt_run',\n",
        "       bash_command='cd /path/to/dbt && dbt run >> logs/dbt_run.log 2>&1',\n",
        "   )\n",
        "\n",
        "5. Conditional execution:\n",
        "   - Skip downstream tasks n·∫øu tests fail\n",
        "   - Use BranchPythonOperator\n",
        "   - Check test results tr∆∞·ªõc khi continue\n",
        "\"\"\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Best Practices\n",
        "\n",
        "Best practices cho dbt + Airflow integration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"‚úÖ Best Practices:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\"\"\n",
        "1. **Separation of Concerns:**\n",
        "   - Airflow: Orchestration v√† scheduling\n",
        "   - dbt: Data transformations\n",
        "   - Don't mix logic\n",
        "\n",
        "2. **Task Granularity:**\n",
        "   - Separate tasks cho staging, marts, tests\n",
        "   - Easier to debug v√† rerun\n",
        "   - Better visibility trong Airflow UI\n",
        "\n",
        "3. **Dependencies:**\n",
        "   - Run staging ‚Üí marts ‚Üí tests\n",
        "   - Use Airflow dependencies properly\n",
        "   - Don't run tests n·∫øu models fail\n",
        "\n",
        "4. **Error Handling:**\n",
        "   - Set appropriate retries\n",
        "   - Handle dbt failures gracefully\n",
        "   - Send alerts cho critical failures\n",
        "\n",
        "5. **Logging:**\n",
        "   - Store dbt logs\n",
        "   - Use Airflow logs\n",
        "   - Make debugging easier\n",
        "\n",
        "6. **Performance:**\n",
        "   - Run models in parallel khi c√≥ th·ªÉ\n",
        "   - Use dbt selectors efficiently\n",
        "   - Monitor execution time\n",
        "\n",
        "7. **Testing:**\n",
        "   - Always run tests sau models\n",
        "   - Fail fast n·∫øu tests fail\n",
        "   - Don't proceed n·∫øu data quality issues\n",
        "\n",
        "8. **Documentation:**\n",
        "   - Generate docs trong pipeline\n",
        "   - Keep docs up-to-date\n",
        "   - Share v·ªõi team\n",
        "\"\"\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. T√≥m t·∫Øt v√† K·∫øt lu·∫≠n\n",
        "\n",
        "### ‚úÖ Nh·ªØng g√¨ ƒë√£ h·ªçc trong to√†n b·ªô dbt Lab Series:\n",
        "\n",
        "**Lab 1: dbt Basics**\n",
        "- dbt l√† g√¨ v√† t·∫°i sao s·ª≠ d·ª•ng\n",
        "- dbt project structure\n",
        "- dbt commands c∆° b·∫£n\n",
        "\n",
        "**Lab 2: Models v√† SQL Transformations**\n",
        "- Staging v√† marts models\n",
        "- Jinja templating\n",
        "- Materializations\n",
        "\n",
        "**Lab 3: Testing v√† Documentation**\n",
        "- Generic v√† custom tests\n",
        "- Documentation\n",
        "- Source freshness\n",
        "\n",
        "**Lab 4: Macros v√† Jinja**\n",
        "- Custom macros\n",
        "- Advanced Jinja\n",
        "- dbt_utils package\n",
        "\n",
        "**Lab 5: Airflow Integration**\n",
        "- T√≠ch h·ª£p dbt v·ªõi Airflow\n",
        "- dbt operators\n",
        "- Error handling\n",
        "\n",
        "### üéØ Key Takeaways:\n",
        "\n",
        "**dbt l√† g√¨:**\n",
        "- Data transformation tool\n",
        "- SQL v·ªõi Jinja templating\n",
        "- Version control cho analytics\n",
        "- Testing v√† documentation\n",
        "\n",
        "**dbt + Airflow:**\n",
        "- Airflow orchestrates\n",
        "- dbt transforms\n",
        "- Together = Complete pipeline\n",
        "\n",
        "**Best Practices:**\n",
        "- Separation of concerns\n",
        "- Proper dependencies\n",
        "- Error handling\n",
        "- Testing v√† documentation\n",
        "\n",
        "### üìö Next Steps:\n",
        "\n",
        "1. **Production Deployment:**\n",
        "   - Setup dbt tr√™n production\n",
        "   - Configure Airflow cho production\n",
        "   - Monitoring v√† alerting\n",
        "\n",
        "2. **Advanced Topics:**\n",
        "   - dbt Cloud\n",
        "   - Python models trong dbt\n",
        "   - Snapshots v√† seeds\n",
        "   - Multi-environment workflows\n",
        "\n",
        "3. **Integration:**\n",
        "   - Cloud data warehouses\n",
        "   - CI/CD cho dbt\n",
        "   - Data quality tools\n",
        "   - BI tools integration\n",
        "\n",
        "### üîó Useful Links:\n",
        "- [dbt Documentation](https://docs.getdbt.com/)\n",
        "- [Airflow dbt Provider](https://airflow.apache.org/docs/apache-airflow-providers-dbt/)\n",
        "- [dbt Best Practices](https://docs.getdbt.com/guides/best-practices)\n",
        "\n",
        "### üéâ Congratulations!\n",
        "\n",
        "B·∫°n ƒë√£ ho√†n th√†nh to√†n b·ªô dbt Lab Series! B√¢y gi·ªù b·∫°n c√≥ ƒë·ªß ki·∫øn th·ª©c ƒë·ªÉ:\n",
        "- Thi·∫øt k·∫ø v√† implement dbt projects\n",
        "- Transform data v·ªõi dbt\n",
        "- Test v√† document data pipelines\n",
        "- T√≠ch h·ª£p dbt v·ªõi Airflow\n",
        "- Deploy v√† maintain production pipelines\n",
        "\n",
        "**Happy Transforming! üöÄ**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
