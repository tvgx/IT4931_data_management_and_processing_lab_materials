{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 5: XCom v√† Data Sharing - Chia s·∫ª D·ªØ li·ªáu gi·ªØa Tasks\n",
        "\n",
        "## üéØ Objectives\n",
        "- Hi·ªÉu XCom (Cross-Communication) trong Airflow\n",
        "- S·ª≠ d·ª•ng task return values ƒë·ªÉ chia s·∫ª data\n",
        "- XCom push v√† pull operations\n",
        "- XCom v·ªõi Task SDK (@task decorator)\n",
        "- XCom v·ªõi Operators (PythonOperator)\n",
        "- Best practices cho data sharing\n",
        "- XCom limitations v√† alternatives\n",
        "\n",
        "## üìã Prerequisites\n",
        "- Ho√†n th√†nh Lab 1-4\n",
        "- Hi·ªÉu task dependencies\n",
        "- Airflow cluster ƒëang ch·∫°y\n",
        "\n",
        "## üèóÔ∏è XCom Overview\n",
        "XCom (Cross-Communication) l√† c∆° ch·∫ø c·ªßa Airflow ƒë·ªÉ chia s·∫ª d·ªØ li·ªáu gi·ªØa tasks:\n",
        "- **XCom Push**: L∆∞u data v√†o XCom\n",
        "- **XCom Pull**: L·∫•y data t·ª´ XCom\n",
        "- **Automatic**: Task return values t·ª± ƒë·ªông ƒë∆∞·ª£c push v√†o XCom\n",
        "- **Manual**: S·ª≠ d·ª•ng `xcom_push()` v√† `xcom_pull()` methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries v√† Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Airflow XCom v√† related modules\n",
        "from airflow.sdk import DAG, task\n",
        "from airflow.providers.standard.operators.python import PythonOperator\n",
        "from airflow.providers.standard.operators.bash import BashOperator\n",
        "\n",
        "import pendulum\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "print(\"‚úÖ Airflow XCom modules imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. XCom v·ªõi Task SDK (@task decorator) - Automatic Return Values\n",
        "\n",
        "V·ªõi Task SDK, return values t·ª± ƒë·ªông ƒë∆∞·ª£c push v√†o XCom. ƒê√¢y l√† c√°ch ƒë∆°n gi·∫£n nh·∫•t ƒë·ªÉ chia s·∫ª data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG v·ªõi Task SDK - Automatic XCom\n",
        "@dag(\n",
        "    dag_id=\"xcom_task_sdk_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"task-sdk\"],\n",
        ")\n",
        "def xcom_task_sdk_dag():\n",
        "    \"\"\"\n",
        "    ### XCom v·ªõi Task SDK\n",
        "    Task SDK t·ª± ƒë·ªông push return values v√†o XCom.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task\n",
        "    def extract_data():\n",
        "        \"\"\"Extract data v√† return - t·ª± ƒë·ªông push v√†o XCom\"\"\"\n",
        "        data = {\n",
        "            \"users\": [\n",
        "                {\"id\": 1, \"name\": \"Alice\", \"age\": 30},\n",
        "                {\"id\": 2, \"name\": \"Bob\", \"age\": 25},\n",
        "                {\"id\": 3, \"name\": \"Charlie\", \"age\": 35},\n",
        "            ],\n",
        "            \"total\": 3,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "        }\n",
        "        print(f\"Extracted {data['total']} users\")\n",
        "        return data  # T·ª± ƒë·ªông push v√†o XCom\n",
        "    \n",
        "    @task\n",
        "    def transform_data(data: dict):\n",
        "        \"\"\"Transform data - nh·∫≠n t·ª´ XCom t·ª± ƒë·ªông\"\"\"\n",
        "        users = data[\"users\"]\n",
        "        \n",
        "        # Calculate statistics\n",
        "        total_age = sum(user[\"age\"] for user in users)\n",
        "        avg_age = total_age / len(users)\n",
        "        \n",
        "        transformed = {\n",
        "            \"total_users\": len(users),\n",
        "            \"average_age\": avg_age,\n",
        "            \"max_age\": max(user[\"age\"] for user in users),\n",
        "            \"min_age\": min(user[\"age\"] for user in users),\n",
        "        }\n",
        "        print(f\"Transformed data: {transformed}\")\n",
        "        return transformed  # T·ª± ƒë·ªông push v√†o XCom\n",
        "    \n",
        "    @task\n",
        "    def load_data(stats: dict):\n",
        "        \"\"\"Load data - nh·∫≠n t·ª´ XCom t·ª± ƒë·ªông\"\"\"\n",
        "        print(f\"Loading statistics:\")\n",
        "        print(f\"  Total users: {stats['total_users']}\")\n",
        "        print(f\"  Average age: {stats['average_age']:.2f}\")\n",
        "        print(f\"  Age range: {stats['min_age']} - {stats['max_age']}\")\n",
        "        return f\"Loaded {stats['total_users']} users successfully\"\n",
        "    \n",
        "    # Define workflow - data t·ª± ƒë·ªông pass qua XCom\n",
        "    extracted = extract_data()\n",
        "    transformed = transform_data(extracted)  # extracted t·ª± ƒë·ªông ƒë∆∞·ª£c pull t·ª´ XCom\n",
        "    load_data(transformed)  # transformed t·ª± ƒë·ªông ƒë∆∞·ª£c pull t·ª´ XCom\n",
        "\n",
        "# Create DAG\n",
        "xcom_task_sdk_dag_instance = xcom_task_sdk_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Task SDK DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_task_sdk_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° V·ªõi Task SDK:\")\n",
        "print(\"  - Return values t·ª± ƒë·ªông push v√†o XCom\")\n",
        "print(\"  - Function parameters t·ª± ƒë·ªông pull t·ª´ XCom\")\n",
        "print(\"  - Kh√¥ng c·∫ßn manual xcom_push/xcom_pull\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. XCom v·ªõi PythonOperator - Manual Push/Pull\n",
        "\n",
        "V·ªõi PythonOperator, b·∫°n c·∫ßn manually push v√† pull XCom values s·ª≠ d·ª•ng `xcom_push()` v√† `xcom_pull()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG v·ªõi PythonOperator - Manual XCom\n",
        "@dag(\n",
        "    dag_id=\"xcom_python_operator_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"python-operator\"],\n",
        ")\n",
        "def xcom_python_operator_dag():\n",
        "    \"\"\"\n",
        "    ### XCom v·ªõi PythonOperator\n",
        "    Manual push v√† pull XCom values v·ªõi PythonOperator.\n",
        "    \"\"\"\n",
        "    \n",
        "    def extract_data(**context):\n",
        "        \"\"\"Extract data v√† push v√†o XCom manually\"\"\"\n",
        "        data = {\n",
        "            \"records\": [1, 2, 3, 4, 5],\n",
        "            \"sum\": 15,\n",
        "        }\n",
        "        \n",
        "        # Manual XCom push\n",
        "        context['ti'].xcom_push(key='extracted_data', value=data)\n",
        "        print(f\"Pushed data to XCom: {data}\")\n",
        "        return \"Extraction completed\"\n",
        "    \n",
        "    def transform_data(**context):\n",
        "        \"\"\"Transform data - pull t·ª´ XCom manually\"\"\"\n",
        "        # Manual XCom pull\n",
        "        data = context['ti'].xcom_pull(key='extracted_data', task_ids='extract_data')\n",
        "        \n",
        "        if data:\n",
        "            # Transform data\n",
        "            transformed = {\n",
        "                \"total_records\": len(data['records']),\n",
        "                \"sum\": data['sum'],\n",
        "                \"average\": data['sum'] / len(data['records']),\n",
        "            }\n",
        "            \n",
        "            # Push transformed data\n",
        "            context['ti'].xcom_push(key='transformed_data', value=transformed)\n",
        "            print(f\"Transformed data: {transformed}\")\n",
        "            return \"Transformation completed\"\n",
        "        else:\n",
        "            raise ValueError(\"No data found in XCom\")\n",
        "    \n",
        "    def load_data(**context):\n",
        "        \"\"\"Load data - pull t·ª´ XCom manually\"\"\"\n",
        "        # Pull t·ª´ task kh√°c\n",
        "        transformed = context['ti'].xcom_pull(key='transformed_data', task_ids='transform_data')\n",
        "        \n",
        "        if transformed:\n",
        "            print(f\"Loading data:\")\n",
        "            print(f\"  Total records: {transformed['total_records']}\")\n",
        "            print(f\"  Sum: {transformed['sum']}\")\n",
        "            print(f\"  Average: {transformed['average']:.2f}\")\n",
        "            return \"Load completed\"\n",
        "        else:\n",
        "            raise ValueError(\"No transformed data found\")\n",
        "    \n",
        "    # Tasks v·ªõi PythonOperator\n",
        "    extract_task = PythonOperator(\n",
        "        task_id=\"extract_data\",\n",
        "        python_callable=extract_data,\n",
        "    )\n",
        "    \n",
        "    transform_task = PythonOperator(\n",
        "        task_id=\"transform_data\",\n",
        "        python_callable=transform_data,\n",
        "    )\n",
        "    \n",
        "    load_task = PythonOperator(\n",
        "        task_id=\"load_data\",\n",
        "        python_callable=load_data,\n",
        "    )\n",
        "    \n",
        "    # Define dependencies\n",
        "    extract_task >> transform_task >> load_task\n",
        "\n",
        "# Create DAG\n",
        "xcom_python_operator_dag_instance = xcom_python_operator_dag()\n",
        "\n",
        "print(\"‚úÖ XCom PythonOperator DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_python_operator_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° V·ªõi PythonOperator:\")\n",
        "print(\"  - S·ª≠ d·ª•ng context['ti'].xcom_push() ƒë·ªÉ push\")\n",
        "print(\"  - S·ª≠ d·ª•ng context['ti'].xcom_pull() ƒë·ªÉ pull\")\n",
        "print(\"  - C·∫ßn specify key v√† task_ids\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. XCom v·ªõi Multiple Return Values\n",
        "\n",
        "Tasks c√≥ th·ªÉ return multiple values ho·∫∑c dictionaries, v√† ch√∫ng s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông push v√†o XCom.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG v·ªõi Multiple Return Values\n",
        "@dag(\n",
        "    dag_id=\"xcom_multiple_values_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"multiple-values\"],\n",
        ")\n",
        "def xcom_multiple_values_dag():\n",
        "    \"\"\"\n",
        "    ### XCom v·ªõi Multiple Return Values\n",
        "    Tasks c√≥ th·ªÉ return dictionaries v·ªõi multiple values.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task(multiple_outputs=True)  # Enable multiple outputs\n",
        "    def extract_multiple_sources():\n",
        "        \"\"\"Extract t·ª´ nhi·ªÅu sources v√† return dictionary\"\"\"\n",
        "        source_a = {\"records\": [1, 2, 3], \"source\": \"A\"}\n",
        "        source_b = {\"records\": [4, 5, 6], \"source\": \"B\"}\n",
        "        \n",
        "        return {\n",
        "            \"source_a\": source_a,\n",
        "            \"source_b\": source_b,\n",
        "            \"total_records\": 6,\n",
        "        }\n",
        "    \n",
        "    @task\n",
        "    def process_source_a(source_a: dict):\n",
        "        \"\"\"Process source A\"\"\"\n",
        "        print(f\"Processing {source_a['source']}: {source_a['records']}\")\n",
        "        return sum(source_a['records'])\n",
        "    \n",
        "    @task\n",
        "    def process_source_b(source_b: dict):\n",
        "        \"\"\"Process source B\"\"\"\n",
        "        print(f\"Processing {source_b['source']}: {source_b['records']}\")\n",
        "        return sum(source_b['records'])\n",
        "    \n",
        "    @task\n",
        "    def aggregate_results(result_a: int, result_b: int):\n",
        "        \"\"\"Aggregate results t·ª´ c·∫£ 2 sources\"\"\"\n",
        "        total = result_a + result_b\n",
        "        print(f\"Aggregated result: {total}\")\n",
        "        return total\n",
        "    \n",
        "    # Extract data v·ªõi multiple outputs\n",
        "    extracted = extract_multiple_sources()\n",
        "    \n",
        "    # Access individual values t·ª´ dictionary\n",
        "    process_a = process_source_a(extracted['source_a'])\n",
        "    process_b = process_source_b(extracted['source_b'])\n",
        "    \n",
        "    # Aggregate\n",
        "    aggregate_results(process_a, process_b)\n",
        "\n",
        "# Create DAG\n",
        "xcom_multiple_values_dag_instance = xcom_multiple_values_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Multiple Values DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_multiple_values_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° Multiple outputs:\")\n",
        "print(\"  - S·ª≠ d·ª•ng @task(multiple_outputs=True)\")\n",
        "print(\"  - Return dictionary v·ªõi multiple keys\")\n",
        "print(\"  - Access values b·∫±ng key: extracted['source_a']\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. XCom v·ªõi Lists v√† Complex Data Structures\n",
        "\n",
        "XCom c√≥ th·ªÉ l∆∞u tr·ªØ lists, dictionaries, v√† c√°c complex data structures (nh∆∞ng c√≥ size limits).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG v·ªõi Complex Data Structures\n",
        "@dag(\n",
        "    dag_id=\"xcom_complex_data_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"complex-data\"],\n",
        ")\n",
        "def xcom_complex_data_dag():\n",
        "    \"\"\"\n",
        "    ### XCom v·ªõi Complex Data Structures\n",
        "    XCom c√≥ th·ªÉ l∆∞u lists, dictionaries, v√† nested structures.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task\n",
        "    def generate_complex_data():\n",
        "        \"\"\"Generate complex nested data structure\"\"\"\n",
        "        data = {\n",
        "            \"metadata\": {\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"version\": \"1.0\",\n",
        "            },\n",
        "            \"users\": [\n",
        "                {\n",
        "                    \"id\": 1,\n",
        "                    \"name\": \"Alice\",\n",
        "                    \"scores\": [95, 87, 92],\n",
        "                    \"metadata\": {\"department\": \"Engineering\"}\n",
        "                },\n",
        "                {\n",
        "                    \"id\": 2,\n",
        "                    \"name\": \"Bob\",\n",
        "                    \"scores\": [78, 85, 90],\n",
        "                    \"metadata\": {\"department\": \"Sales\"}\n",
        "                },\n",
        "            ],\n",
        "            \"statistics\": {\n",
        "                \"total_users\": 2,\n",
        "                \"average_score\": 88.5,\n",
        "            }\n",
        "        }\n",
        "        print(f\"Generated complex data with {data['statistics']['total_users']} users\")\n",
        "        return data\n",
        "    \n",
        "    @task\n",
        "    def process_users(complex_data: dict):\n",
        "        \"\"\"Process users t·ª´ complex data\"\"\"\n",
        "        users = complex_data['users']\n",
        "        \n",
        "        results = []\n",
        "        for user in users:\n",
        "            avg_score = sum(user['scores']) / len(user['scores'])\n",
        "            results.append({\n",
        "                \"user_id\": user['id'],\n",
        "                \"name\": user['name'],\n",
        "                \"average_score\": avg_score,\n",
        "                \"department\": user['metadata']['department']\n",
        "            })\n",
        "        \n",
        "        print(f\"Processed {len(results)} users\")\n",
        "        return results\n",
        "    \n",
        "    @task\n",
        "    def generate_report(user_results: list, metadata: dict):\n",
        "        \"\"\"Generate report t·ª´ processed data\"\"\"\n",
        "        print(\"=\" * 60)\n",
        "        print(\"User Performance Report\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Generated at: {metadata['timestamp']}\")\n",
        "        print(f\"Version: {metadata['version']}\")\n",
        "        print(\"\\nUser Details:\")\n",
        "        for result in user_results:\n",
        "            print(f\"  {result['name']} ({result['department']}): {result['average_score']:.2f}\")\n",
        "        print(\"=\" * 60)\n",
        "        return \"Report generated\"\n",
        "    \n",
        "    # Extract complex data\n",
        "    complex_data = generate_complex_data()\n",
        "    \n",
        "    # Process users\n",
        "    user_results = process_users(complex_data)\n",
        "    \n",
        "    # Generate report v·ªõi multiple inputs\n",
        "    generate_report(user_results, complex_data['metadata'])\n",
        "\n",
        "# Create DAG\n",
        "xcom_complex_data_dag_instance = xcom_complex_data_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Complex Data DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_complex_data_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° Complex data structures:\")\n",
        "print(\"  - XCom h·ªó tr·ª£ nested dictionaries v√† lists\")\n",
        "print(\"  - C√≥ th·ªÉ access nested values: data['metadata']['timestamp']\")\n",
        "print(\"  - L∆∞u √Ω: XCom c√≥ size limits (default: 48KB)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. XCom Pull t·ª´ Multiple Tasks\n",
        "\n",
        "M·ªôt task c√≥ th·ªÉ pull XCom values t·ª´ nhi·ªÅu upstream tasks kh√°c nhau.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG v·ªõi XCom t·ª´ Multiple Tasks\n",
        "@dag(\n",
        "    dag_id=\"xcom_multiple_tasks_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"multiple-tasks\"],\n",
        ")\n",
        "def xcom_multiple_tasks_dag():\n",
        "    \"\"\"\n",
        "    ### XCom t·ª´ Multiple Tasks\n",
        "    Pull XCom values t·ª´ nhi·ªÅu upstream tasks.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task\n",
        "    def extract_source_a():\n",
        "        \"\"\"Extract t·ª´ source A\"\"\"\n",
        "        data = {\"source\": \"A\", \"records\": [1, 2, 3], \"sum\": 6}\n",
        "        print(f\"Extracted from source A: {data}\")\n",
        "        return data\n",
        "    \n",
        "    @task\n",
        "    def extract_source_b():\n",
        "        \"\"\"Extract t·ª´ source B\"\"\"\n",
        "        data = {\"source\": \"B\", \"records\": [4, 5, 6], \"sum\": 15}\n",
        "        print(f\"Extracted from source B: {data}\")\n",
        "        return data\n",
        "    \n",
        "    @task\n",
        "    def extract_source_c():\n",
        "        \"\"\"Extract t·ª´ source C\"\"\"\n",
        "        data = {\"source\": \"C\", \"records\": [7, 8, 9], \"sum\": 24}\n",
        "        print(f\"Extracted from source C: {data}\")\n",
        "        return data\n",
        "    \n",
        "    @task\n",
        "    def merge_data(source_a: dict, source_b: dict, source_c: dict):\n",
        "        \"\"\"Merge data t·ª´ c·∫£ 3 sources\"\"\"\n",
        "        all_records = (\n",
        "            source_a['records'] + \n",
        "            source_b['records'] + \n",
        "            source_c['records']\n",
        "        )\n",
        "        total_sum = source_a['sum'] + source_b['sum'] + source_c['sum']\n",
        "        \n",
        "        merged = {\n",
        "            \"all_records\": all_records,\n",
        "            \"total_sum\": total_sum,\n",
        "            \"total_records\": len(all_records),\n",
        "            \"sources\": [source_a['source'], source_b['source'], source_c['source']]\n",
        "        }\n",
        "        \n",
        "        print(f\"Merged data: {merged}\")\n",
        "        return merged\n",
        "    \n",
        "    @task\n",
        "    def finalize(merged_data: dict):\n",
        "        \"\"\"Finalize v·ªõi merged data\"\"\"\n",
        "        print(f\"Finalizing with {merged_data['total_records']} records\")\n",
        "        print(f\"Total sum: {merged_data['total_sum']}\")\n",
        "        print(f\"Sources: {', '.join(merged_data['sources'])}\")\n",
        "        return \"Finalized\"\n",
        "    \n",
        "    # Extract t·ª´ nhi·ªÅu sources (parallel)\n",
        "    source_a_data = extract_source_a()\n",
        "    source_b_data = extract_source_b()\n",
        "    source_c_data = extract_source_c()\n",
        "    \n",
        "    # Merge data t·ª´ c·∫£ 3 sources\n",
        "    merged = merge_data(source_a_data, source_b_data, source_c_data)\n",
        "    \n",
        "    # Finalize\n",
        "    finalize(merged)\n",
        "\n",
        "# Create DAG\n",
        "xcom_multiple_tasks_dag_instance = xcom_multiple_tasks_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Multiple Tasks DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_multiple_tasks_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° Multiple upstream tasks:\")\n",
        "print(\"  - Task c√≥ th·ªÉ nh·∫≠n inputs t·ª´ nhi·ªÅu upstream tasks\")\n",
        "print(\"  - Function parameters map v·ªõi return values t·ª´ upstream tasks\")\n",
        "print(\"  - T·∫•t c·∫£ upstream tasks ph·∫£i complete tr∆∞·ªõc khi task n√†y ch·∫°y\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG minh h·ªça XCom Best Practices\n",
        "@dag(\n",
        "    dag_id=\"xcom_best_practices_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"best-practices\"],\n",
        ")\n",
        "def xcom_best_practices_dag():\n",
        "    \"\"\"\n",
        "    ### XCom Best Practices Example\n",
        "    Minh h·ªça best practices khi s·ª≠ d·ª•ng XCom.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task\n",
        "    def extract_metadata_only():\n",
        "        \"\"\"\n",
        "        ‚úÖ Best Practice: Ch·ªâ pass metadata, kh√¥ng pass large data\n",
        "        Thay v√¨ pass to√†n b·ªô data, ch·ªâ pass file path ho·∫∑c reference\n",
        "        \"\"\"\n",
        "        # Simulate: Thay v√¨ pass large dataset, ch·ªâ pass file path\n",
        "        file_path = \"/tmp/data/large_dataset.parquet\"\n",
        "        metadata = {\n",
        "            \"file_path\": file_path,\n",
        "            \"record_count\": 1000000,\n",
        "            \"file_size_mb\": 250,\n",
        "            \"schema\": [\"id\", \"name\", \"value\"],\n",
        "        }\n",
        "        print(f\"Extracted metadata: {metadata}\")\n",
        "        return metadata  # Ch·ªâ pass metadata, kh√¥ng pass data\n",
        "    \n",
        "    @task\n",
        "    def process_file(metadata: dict):\n",
        "        \"\"\"\n",
        "        ‚úÖ Best Practice: Process file t·ª´ path, kh√¥ng t·ª´ XCom\n",
        "        \"\"\"\n",
        "        file_path = metadata['file_path']\n",
        "        print(f\"Processing file: {file_path}\")\n",
        "        print(f\"Records: {metadata['record_count']}\")\n",
        "        # In th·ª±c t·∫ø, ƒë·ªçc file t·ª´ path v√† process\n",
        "        return {\"status\": \"processed\", \"records_processed\": metadata['record_count']}\n",
        "    \n",
        "    @task\n",
        "    def store_summary(summary: dict):\n",
        "        \"\"\"\n",
        "        ‚úÖ Best Practice: Ch·ªâ store summary/aggregated data\n",
        "        \"\"\"\n",
        "        print(f\"Storing summary: {summary}\")\n",
        "        return \"Summary stored\"\n",
        "    \n",
        "    # Workflow v·ªõi best practices\n",
        "    metadata = extract_metadata_only()\n",
        "    summary = process_file(metadata)\n",
        "    store_summary(summary)\n",
        "\n",
        "# Create DAG\n",
        "xcom_best_practices_dag_instance = xcom_best_practices_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Best Practices DAG created!\")\n",
        "print(\"\\nüìã XCom Best Practices:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"‚úÖ DO:\")\n",
        "print(\"  - Ch·ªâ pass small data (< 48KB)\")\n",
        "print(\"  - Pass metadata/references thay v√¨ large datasets\")\n",
        "print(\"  - Pass file paths thay v√¨ file contents\")\n",
        "print(\"  - Pass aggregated/summary data\")\n",
        "print(\"  - S·ª≠ d·ª•ng Task SDK cho automatic XCom\")\n",
        "print(\"\\n‚ùå DON'T:\")\n",
        "print(\"  - Pass large datasets qua XCom\")\n",
        "print(\"  - Pass binary data qua XCom\")\n",
        "print(\"  - Pass sensitive data (use Variables/Connections)\")\n",
        "print(\"  - Rely on XCom cho data storage\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nüí° Alternatives cho Large Data:\")\n",
        "print(\"  - File storage (S3, GCS, local files)\")\n",
        "print(\"  - Databases\")\n",
        "print(\"  - External storage systems\")\n",
        "print(\"  - Pass only references/IDs qua XCom\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. XCom v·ªõi Task Mapping v√† Dynamic Tasks\n",
        "\n",
        "XCom ho·∫°t ƒë·ªông t·ªët v·ªõi dynamic task mapping - m·ªói mapped task instance c√≥ XCom ri√™ng.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG v·ªõi XCom v√† Task Mapping\n",
        "@dag(\n",
        "    dag_id=\"xcom_task_mapping_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"task-mapping\"],\n",
        ")\n",
        "def xcom_task_mapping_dag():\n",
        "    \"\"\"\n",
        "    ### XCom v·ªõi Task Mapping\n",
        "    XCom ho·∫°t ƒë·ªông v·ªõi dynamic task mapping.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task\n",
        "    def get_files_to_process():\n",
        "        \"\"\"Get list of files to process\"\"\"\n",
        "        files = [\n",
        "            {\"path\": \"/data/file1.csv\", \"size\": 1000},\n",
        "            {\"path\": \"/data/file2.csv\", \"size\": 2000},\n",
        "            {\"path\": \"/data/file3.csv\", \"size\": 1500},\n",
        "        ]\n",
        "        print(f\"Found {len(files)} files to process\")\n",
        "        return files\n",
        "    \n",
        "    @task\n",
        "    def process_file(file_info: dict):\n",
        "        \"\"\"Process m·ªôt file - s·∫Ω ƒë∆∞·ª£c map cho m·ªói file\"\"\"\n",
        "        file_path = file_info['path']\n",
        "        file_size = file_info['size']\n",
        "        \n",
        "        # Simulate processing\n",
        "        records_processed = file_size // 100\n",
        "        \n",
        "        result = {\n",
        "            \"file_path\": file_path,\n",
        "            \"records_processed\": records_processed,\n",
        "            \"status\": \"success\"\n",
        "        }\n",
        "        \n",
        "        print(f\"Processed {file_path}: {records_processed} records\")\n",
        "        return result\n",
        "    \n",
        "    @task\n",
        "    def aggregate_results(results: list):\n",
        "        \"\"\"Aggregate results t·ª´ t·∫•t c·∫£ mapped tasks\"\"\"\n",
        "        total_records = sum(r['records_processed'] for r in results)\n",
        "        total_files = len(results)\n",
        "        \n",
        "        summary = {\n",
        "            \"total_files\": total_files,\n",
        "            \"total_records\": total_records,\n",
        "            \"average_records_per_file\": total_records / total_files if total_files > 0 else 0\n",
        "        }\n",
        "        \n",
        "        print(f\"Aggregated summary: {summary}\")\n",
        "        return summary\n",
        "    \n",
        "    # Get files\n",
        "    files = get_files_to_process()\n",
        "    \n",
        "    # Process files v·ªõi dynamic mapping\n",
        "    # M·ªói mapped task instance s·∫Ω c√≥ XCom ri√™ng\n",
        "    processed_files = process_file.expand(file_info=files)\n",
        "    \n",
        "    # Aggregate - nh·∫≠n list c·ªßa t·∫•t c·∫£ results\n",
        "    aggregate_results(processed_files)\n",
        "\n",
        "# Create DAG\n",
        "xcom_task_mapping_dag_instance = xcom_task_mapping_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Task Mapping DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_task_mapping_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° XCom v·ªõi Task Mapping:\")\n",
        "print(\"  - M·ªói mapped task instance c√≥ XCom ri√™ng\")\n",
        "print(\"  - Aggregate task nh·∫≠n list c·ªßa t·∫•t c·∫£ results\")\n",
        "print(\"  - XCom key t·ª± ƒë·ªông include map index\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. T√≥m t·∫Øt v√† Next Steps\n",
        "\n",
        "### ‚úÖ Nh·ªØng g√¨ ƒë√£ h·ªçc:\n",
        "1. XCom basics - Cross-communication gi·ªØa tasks\n",
        "2. Task SDK automatic XCom - Return values t·ª± ƒë·ªông\n",
        "3. PythonOperator manual XCom - Push/pull operations\n",
        "4. Multiple return values v·ªõi dictionaries\n",
        "5. Complex data structures trong XCom\n",
        "6. Pull t·ª´ multiple upstream tasks\n",
        "7. XCom limitations v√† best practices\n",
        "8. XCom v·ªõi task mapping\n",
        "\n",
        "### üìö Next Lab:\n",
        "- **Lab 6**: Scheduling v√† Timetables\n",
        "- Cron expressions\n",
        "- Timedelta schedules\n",
        "- Custom timetables\n",
        "- Catchup v√† data intervals\n",
        "\n",
        "### üîó Useful Links:\n",
        "- [XCom Documentation](https://airflow.apache.org/docs/apache-airflow/3.1.1/core-concepts/xcoms.html)\n",
        "- [Task SDK XCom](https://airflow.apache.org/docs/apache-airflow/3.1.1/task-sdk/index.html)\n",
        "- [XCom Best Practices](https://airflow.apache.org/docs/apache-airflow/3.1.1/best-practices.html#xcom)\n",
        "\n",
        "### üí° Key Takeaways:\n",
        "\n",
        "**XCom Size Limits:**\n",
        "- Default: 48KB per value\n",
        "- Configurable via `xcom_max_value_size`\n",
        "- Kh√¥ng n√™n pass large data\n",
        "\n",
        "**Best Practices:**\n",
        "- ‚úÖ Pass metadata/references\n",
        "- ‚úÖ Pass file paths thay v√¨ contents\n",
        "- ‚úÖ Use Task SDK cho automatic XCom\n",
        "- ‚ùå Don't pass large datasets\n",
        "- ‚ùå Don't use XCom nh∆∞ database\n",
        "\n",
        "**Alternatives:**\n",
        "- File storage (S3, GCS, local)\n",
        "- Databases\n",
        "- External APIs\n",
        "- Airflow Variables (cho config)\n",
        "\n",
        "### üí° Exercises:\n",
        "1. T·∫°o DAG v·ªõi XCom passing metadata gi·ªØa tasks\n",
        "2. Implement data pipeline v·ªõi file paths qua XCom\n",
        "3. S·ª≠ d·ª•ng multiple return values\n",
        "4. Combine XCom v·ªõi task mapping\n",
        "5. Implement error handling v·ªõi XCom\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
