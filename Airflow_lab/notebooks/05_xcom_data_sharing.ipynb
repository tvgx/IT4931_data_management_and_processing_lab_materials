{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 5: XCom and Data Sharing - Sharing Data Between Tasks\n",
        "\n",
        "## üéØ Objectives\n",
        "- Understand XCom (Cross-Communication) in Airflow\n",
        "- Use task return values to share data\n",
        "- XCom push and pull operations\n",
        "- XCom with Task SDK (@task decorator)\n",
        "- XCom with Operators (PythonOperator)\n",
        "- Best practices for data sharing\n",
        "- XCom limitations and alternatives\n",
        "\n",
        "## üìã Prerequisites\n",
        "- Completed Lab 1-4\n",
        "- Understand task dependencies\n",
        "- Airflow cluster is running\n",
        "\n",
        "## üèóÔ∏è XCom Overview\n",
        "XCom (Cross-Communication) is Airflow's mechanism for sharing data between tasks:\n",
        "- **XCom Push**: Save data to XCom\n",
        "- **XCom Pull**: Get data from XCom\n",
        "- **Automatic**: Task return values are automatically pushed to XCom\n",
        "- **Manual**: Use `xcom_push()` and `xcom_pull()` methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Airflow XCom and related modules\n",
        "from airflow.sdk import DAG, task\n",
        "from airflow.providers.standard.operators.python import PythonOperator\n",
        "from airflow.providers.standard.operators.bash import BashOperator\n",
        "\n",
        "import pendulum\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "print(\"‚úÖ Airflow XCom modules imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. XCom with Task SDK (@task decorator) - Automatic Return Values\n",
        "\n",
        "With Task SDK, return values are automatically pushed to XCom. This is the simplest way to share data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG with Task SDK - Automatic XCom\n",
        "@dag(\n",
        "    dag_id=\"xcom_task_sdk_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"task-sdk\"],\n",
        ")\n",
        "def xcom_task_sdk_dag():\n",
        "    \"\"\"\n",
        "    ### XCom with Task SDK\n",
        "    Task SDK automatically pushes return values to XCom.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task\n",
        "    def extract_data():\n",
        "        \"\"\"Extract data and return - automatically pushed to XCom\"\"\"\n",
        "        data = {\n",
        "            \"users\": [\n",
        "                {\"id\": 1, \"name\": \"Alice\", \"age\": 30},\n",
        "                {\"id\": 2, \"name\": \"Bob\", \"age\": 25},\n",
        "                {\"id\": 3, \"name\": \"Charlie\", \"age\": 35},\n",
        "            ],\n",
        "            \"total\": 3,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "        }\n",
        "        print(f\"Extracted {data['total']} users\")\n",
        "        return data  # Automatically pushed to XCom\n",
        "    \n",
        "    @task\n",
        "    def transform_data(data: dict):\n",
        "        \"\"\"Transform data - automatically received from XCom\"\"\"\n",
        "        users = data[\"users\"]\n",
        "        \n",
        "        # Calculate statistics\n",
        "        total_age = sum(user[\"age\"] for user in users)\n",
        "        avg_age = total_age / len(users)\n",
        "        \n",
        "        transformed = {\n",
        "            \"total_users\": len(users),\n",
        "            \"average_age\": avg_age,\n",
        "            \"max_age\": max(user[\"age\"] for user in users),\n",
        "            \"min_age\": min(user[\"age\"] for user in users),\n",
        "        }\n",
        "        print(f\"Transformed data: {transformed}\")\n",
        "        return transformed  # Automatically pushed to XCom\n",
        "    \n",
        "    @task\n",
        "    def load_data(stats: dict):\n",
        "        \"\"\"Load data - automatically received from XCom\"\"\"\n",
        "        print(f\"Loading statistics:\")\n",
        "        print(f\"  Total users: {stats['total_users']}\")\n",
        "        print(f\"  Average age: {stats['average_age']:.2f}\")\n",
        "        print(f\"  Age range: {stats['min_age']} - {stats['max_age']}\")\n",
        "        return f\"Loaded {stats['total_users']} users successfully\"\n",
        "    \n",
        "    # Define workflow - data automatically passes through XCom\n",
        "    extracted = extract_data()\n",
        "    transformed = transform_data(extracted)  # extracted automatically pulled from XCom\n",
        "    load_data(transformed)  # transformed automatically pulled from XCom\n",
        "\n",
        "# Create DAG\n",
        "xcom_task_sdk_dag_instance = xcom_task_sdk_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Task SDK DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_task_sdk_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° V·ªõi Task SDK:\")\n",
        "print(\"  - Return values t·ª± ƒë·ªông push v√†o XCom\")\n",
        "print(\"  - Function parameters t·ª± ƒë·ªông pull t·ª´ XCom\")\n",
        "print(\"  - Kh√¥ng c·∫ßn manual xcom_push/xcom_pull\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. XCom with PythonOperator - Manual Push/Pull\n",
        "\n",
        "With PythonOperator, you need to manually push and pull XCom values using `xcom_push()` and `xcom_pull()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG with PythonOperator - Manual XCom\n",
        "@dag(\n",
        "    dag_id=\"xcom_python_operator_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"python-operator\"],\n",
        ")\n",
        "def xcom_python_operator_dag():\n",
        "    \"\"\"\n",
        "    ### XCom with PythonOperator\n",
        "    Manually push and pull XCom values with PythonOperator.\n",
        "    \"\"\"\n",
        "    \n",
        "    def extract_data(**context):\n",
        "        \"\"\"Extract data and push to XCom manually\"\"\"\n",
        "        data = {\n",
        "            \"records\": [1, 2, 3, 4, 5],\n",
        "            \"sum\": 15,\n",
        "        }\n",
        "        \n",
        "        # Manual XCom push\n",
        "        context['ti'].xcom_push(key='extracted_data', value=data)\n",
        "        print(f\"Pushed data to XCom: {data}\")\n",
        "        return \"Extraction completed\"\n",
        "    \n",
        "    def transform_data(**context):\n",
        "        \"\"\"Transform data - pull from XCom manually\"\"\"\n",
        "        # Manual XCom pull\n",
        "        data = context['ti'].xcom_pull(key='extracted_data', task_ids='extract_data')\n",
        "        \n",
        "        if data:\n",
        "            # Transform data\n",
        "            transformed = {\n",
        "                \"total_records\": len(data['records']),\n",
        "                \"sum\": data['sum'],\n",
        "                \"average\": data['sum'] / len(data['records']),\n",
        "            }\n",
        "            \n",
        "            # Push transformed data\n",
        "            context['ti'].xcom_push(key='transformed_data', value=transformed)\n",
        "            print(f\"Transformed data: {transformed}\")\n",
        "            return \"Transformation completed\"\n",
        "        else:\n",
        "            raise ValueError(\"No data found in XCom\")\n",
        "    \n",
        "    def load_data(**context):\n",
        "        \"\"\"Load data - pull from XCom manually\"\"\"\n",
        "        # Pull from another task\n",
        "        transformed = context['ti'].xcom_pull(key='transformed_data', task_ids='transform_data')\n",
        "        \n",
        "        if transformed:\n",
        "            print(f\"Loading data:\")\n",
        "            print(f\"  Total records: {transformed['total_records']}\")\n",
        "            print(f\"  Sum: {transformed['sum']}\")\n",
        "            print(f\"  Average: {transformed['average']:.2f}\")\n",
        "            return \"Load completed\"\n",
        "        else:\n",
        "            raise ValueError(\"No transformed data found\")\n",
        "    \n",
        "    # Tasks v·ªõi PythonOperator\n",
        "    extract_task = PythonOperator(\n",
        "        task_id=\"extract_data\",\n",
        "        python_callable=extract_data,\n",
        "    )\n",
        "    \n",
        "    transform_task = PythonOperator(\n",
        "        task_id=\"transform_data\",\n",
        "        python_callable=transform_data,\n",
        "    )\n",
        "    \n",
        "    load_task = PythonOperator(\n",
        "        task_id=\"load_data\",\n",
        "        python_callable=load_data,\n",
        "    )\n",
        "    \n",
        "    # Define dependencies\n",
        "    extract_task >> transform_task >> load_task\n",
        "\n",
        "# Create DAG\n",
        "xcom_python_operator_dag_instance = xcom_python_operator_dag()\n",
        "\n",
        "print(\"‚úÖ XCom PythonOperator DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_python_operator_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° V·ªõi PythonOperator:\")\n",
        "print(\"  - S·ª≠ d·ª•ng context['ti'].xcom_push() ƒë·ªÉ push\")\n",
        "print(\"  - S·ª≠ d·ª•ng context['ti'].xcom_pull() ƒë·ªÉ pull\")\n",
        "print(\"  - C·∫ßn specify key v√† task_ids\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. XCom with Multiple Return Values\n",
        "\n",
        "Tasks can return multiple values or dictionaries, and they will be automatically pushed to XCom.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG with Multiple Return Values\n",
        "@dag(\n",
        "    dag_id=\"xcom_multiple_values_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"multiple-values\"],\n",
        ")\n",
        "def xcom_multiple_values_dag():\n",
        "    \"\"\"\n",
        "    ### XCom with Multiple Return Values\n",
        "    Tasks can return dictionaries with multiple values.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task(multiple_outputs=True)  # Enable multiple outputs\n",
        "    def extract_multiple_sources():\n",
        "        \"\"\"Extract from multiple sources and return dictionary\"\"\"\n",
        "        source_a = {\"records\": [1, 2, 3], \"source\": \"A\"}\n",
        "        source_b = {\"records\": [4, 5, 6], \"source\": \"B\"}\n",
        "        \n",
        "        return {\n",
        "            \"source_a\": source_a,\n",
        "            \"source_b\": source_b,\n",
        "            \"total_records\": 6,\n",
        "        }\n",
        "    \n",
        "    @task\n",
        "    def process_source_a(source_a: dict):\n",
        "        \"\"\"Process source A\"\"\"\n",
        "        print(f\"Processing {source_a['source']}: {source_a['records']}\")\n",
        "        return sum(source_a['records'])\n",
        "    \n",
        "    @task\n",
        "    def process_source_b(source_b: dict):\n",
        "        \"\"\"Process source B\"\"\"\n",
        "        print(f\"Processing {source_b['source']}: {source_b['records']}\")\n",
        "        return sum(source_b['records'])\n",
        "    \n",
        "    @task\n",
        "    def aggregate_results(result_a: int, result_b: int):\n",
        "        \"\"\"Aggregate results from both sources\"\"\"\n",
        "        total = result_a + result_b\n",
        "        print(f\"Aggregated result: {total}\")\n",
        "        return total\n",
        "    \n",
        "    # Extract data with multiple outputs\n",
        "    extracted = extract_multiple_sources()\n",
        "    \n",
        "    # Access individual values from dictionary\n",
        "    process_a = process_source_a(extracted['source_a'])\n",
        "    process_b = process_source_b(extracted['source_b'])\n",
        "    \n",
        "    # Aggregate\n",
        "    aggregate_results(process_a, process_b)\n",
        "\n",
        "# Create DAG\n",
        "xcom_multiple_values_dag_instance = xcom_multiple_values_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Multiple Values DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_multiple_values_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° Multiple outputs:\")\n",
        "print(\"  - S·ª≠ d·ª•ng @task(multiple_outputs=True)\")\n",
        "print(\"  - Return dictionary v·ªõi multiple keys\")\n",
        "print(\"  - Access values b·∫±ng key: extracted['source_a']\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. XCom with Lists and Complex Data Structures\n",
        "\n",
        "XCom can store lists, dictionaries, and complex data structures (but has size limits).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG with Complex Data Structures\n",
        "@dag(\n",
        "    dag_id=\"xcom_complex_data_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"complex-data\"],\n",
        ")\n",
        "def xcom_complex_data_dag():\n",
        "    \"\"\"\n",
        "    ### XCom with Complex Data Structures\n",
        "    XCom can store lists, dictionaries, and nested structures.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task\n",
        "    def generate_complex_data():\n",
        "        \"\"\"Generate complex nested data structure\"\"\"\n",
        "        data = {\n",
        "            \"metadata\": {\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"version\": \"1.0\",\n",
        "            },\n",
        "            \"users\": [\n",
        "                {\n",
        "                    \"id\": 1,\n",
        "                    \"name\": \"Alice\",\n",
        "                    \"scores\": [95, 87, 92],\n",
        "                    \"metadata\": {\"department\": \"Engineering\"}\n",
        "                },\n",
        "                {\n",
        "                    \"id\": 2,\n",
        "                    \"name\": \"Bob\",\n",
        "                    \"scores\": [78, 85, 90],\n",
        "                    \"metadata\": {\"department\": \"Sales\"}\n",
        "                },\n",
        "            ],\n",
        "            \"statistics\": {\n",
        "                \"total_users\": 2,\n",
        "                \"average_score\": 88.5,\n",
        "            }\n",
        "        }\n",
        "        print(f\"Generated complex data with {data['statistics']['total_users']} users\")\n",
        "        return data\n",
        "    \n",
        "    @task\n",
        "    def process_users(complex_data: dict):\n",
        "        \"\"\"Process users from complex data\"\"\"\n",
        "        users = complex_data['users']\n",
        "        \n",
        "        results = []\n",
        "        for user in users:\n",
        "            avg_score = sum(user['scores']) / len(user['scores'])\n",
        "            results.append({\n",
        "                \"user_id\": user['id'],\n",
        "                \"name\": user['name'],\n",
        "                \"average_score\": avg_score,\n",
        "                \"department\": user['metadata']['department']\n",
        "            })\n",
        "        \n",
        "        print(f\"Processed {len(results)} users\")\n",
        "        return results\n",
        "    \n",
        "    @task\n",
        "    def generate_report(user_results: list, metadata: dict):\n",
        "        \"\"\"Generate report from processed data\"\"\"\n",
        "        print(\"=\" * 60)\n",
        "        print(\"User Performance Report\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Generated at: {metadata['timestamp']}\")\n",
        "        print(f\"Version: {metadata['version']}\")\n",
        "        print(\"\\nUser Details:\")\n",
        "        for result in user_results:\n",
        "            print(f\"  {result['name']} ({result['department']}): {result['average_score']:.2f}\")\n",
        "        print(\"=\" * 60)\n",
        "        return \"Report generated\"\n",
        "    \n",
        "    # Extract complex data\n",
        "    complex_data = generate_complex_data()\n",
        "    \n",
        "    # Process users\n",
        "    user_results = process_users(complex_data)\n",
        "    \n",
        "    # Generate report v·ªõi multiple inputs\n",
        "    generate_report(user_results, complex_data['metadata'])\n",
        "\n",
        "# Create DAG\n",
        "xcom_complex_data_dag_instance = xcom_complex_data_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Complex Data DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_complex_data_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° Complex data structures:\")\n",
        "print(\"  - XCom h·ªó tr·ª£ nested dictionaries v√† lists\")\n",
        "print(\"  - C√≥ th·ªÉ access nested values: data['metadata']['timestamp']\")\n",
        "print(\"  - L∆∞u √Ω: XCom c√≥ size limits (default: 48KB)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. XCom Pull from Multiple Tasks\n",
        "\n",
        "A task can pull XCom values from multiple different upstream tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG with XCom from Multiple Tasks\n",
        "@dag(\n",
        "    dag_id=\"xcom_multiple_tasks_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"multiple-tasks\"],\n",
        ")\n",
        "def xcom_multiple_tasks_dag():\n",
        "    \"\"\"\n",
        "    ### XCom from Multiple Tasks\n",
        "    Pull XCom values from multiple upstream tasks.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task\n",
        "    def extract_source_a():\n",
        "        \"\"\"Extract from source A\"\"\"\n",
        "        data = {\"source\": \"A\", \"records\": [1, 2, 3], \"sum\": 6}\n",
        "        print(f\"Extracted from source A: {data}\")\n",
        "        return data\n",
        "    \n",
        "    @task\n",
        "    def extract_source_b():\n",
        "        \"\"\"Extract from source B\"\"\"\n",
        "        data = {\"source\": \"B\", \"records\": [4, 5, 6], \"sum\": 15}\n",
        "        print(f\"Extracted from source B: {data}\")\n",
        "        return data\n",
        "    \n",
        "    @task\n",
        "    def extract_source_c():\n",
        "        \"\"\"Extract from source C\"\"\"\n",
        "        data = {\"source\": \"C\", \"records\": [7, 8, 9], \"sum\": 24}\n",
        "        print(f\"Extracted from source C: {data}\")\n",
        "        return data\n",
        "    \n",
        "    @task\n",
        "    def merge_data(source_a: dict, source_b: dict, source_c: dict):\n",
        "        \"\"\"Merge data from all 3 sources\"\"\"\n",
        "        all_records = (\n",
        "            source_a['records'] + \n",
        "            source_b['records'] + \n",
        "            source_c['records']\n",
        "        )\n",
        "        total_sum = source_a['sum'] + source_b['sum'] + source_c['sum']\n",
        "        \n",
        "        merged = {\n",
        "            \"all_records\": all_records,\n",
        "            \"total_sum\": total_sum,\n",
        "            \"total_records\": len(all_records),\n",
        "            \"sources\": [source_a['source'], source_b['source'], source_c['source']]\n",
        "        }\n",
        "        \n",
        "        print(f\"Merged data: {merged}\")\n",
        "        return merged\n",
        "    \n",
        "    @task\n",
        "    def finalize(merged_data: dict):\n",
        "        \"\"\"Finalize with merged data\"\"\"\n",
        "        print(f\"Finalizing with {merged_data['total_records']} records\")\n",
        "        print(f\"Total sum: {merged_data['total_sum']}\")\n",
        "        print(f\"Sources: {', '.join(merged_data['sources'])}\")\n",
        "        return \"Finalized\"\n",
        "    \n",
        "    # Extract from multiple sources (parallel)\n",
        "    source_a_data = extract_source_a()\n",
        "    source_b_data = extract_source_b()\n",
        "    source_c_data = extract_source_c()\n",
        "    \n",
        "    # Merge data from all 3 sources\n",
        "    merged = merge_data(source_a_data, source_b_data, source_c_data)\n",
        "    \n",
        "    # Finalize\n",
        "    finalize(merged)\n",
        "\n",
        "# Create DAG\n",
        "xcom_multiple_tasks_dag_instance = xcom_multiple_tasks_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Multiple Tasks DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_multiple_tasks_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° Multiple upstream tasks:\")\n",
        "print(\"  - Task c√≥ th·ªÉ nh·∫≠n inputs t·ª´ nhi·ªÅu upstream tasks\")\n",
        "print(\"  - Function parameters map v·ªõi return values t·ª´ upstream tasks\")\n",
        "print(\"  - T·∫•t c·∫£ upstream tasks ph·∫£i complete tr∆∞·ªõc khi task n√†y ch·∫°y\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG demonstrating XCom Best Practices\n",
        "@dag(\n",
        "    dag_id=\"xcom_best_practices_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"best-practices\"],\n",
        ")\n",
        "def xcom_best_practices_dag():\n",
        "    \"\"\"\n",
        "    ### XCom Best Practices Example\n",
        "    Demonstrates best practices when using XCom.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task\n",
        "    def extract_metadata_only():\n",
        "        \"\"\"\n",
        "        ‚úÖ Best Practice: Only pass metadata, don't pass large data\n",
        "        Instead of passing entire dataset, only pass file path or reference\n",
        "        \"\"\"\n",
        "        # Simulate: Instead of passing large dataset, only pass file path\n",
        "        file_path = \"/tmp/data/large_dataset.parquet\"\n",
        "        metadata = {\n",
        "            \"file_path\": file_path,\n",
        "            \"record_count\": 1000000,\n",
        "            \"file_size_mb\": 250,\n",
        "            \"schema\": [\"id\", \"name\", \"value\"],\n",
        "        }\n",
        "        print(f\"Extracted metadata: {metadata}\")\n",
        "        return metadata  # Only pass metadata, not data\n",
        "    \n",
        "    @task\n",
        "    def process_file(metadata: dict):\n",
        "        \"\"\"\n",
        "        ‚úÖ Best Practice: Process file from path, not from XCom\n",
        "        \"\"\"\n",
        "        file_path = metadata['file_path']\n",
        "        print(f\"Processing file: {file_path}\")\n",
        "        print(f\"Records: {metadata['record_count']}\")\n",
        "        # In practice, read file from path and process\n",
        "        return {\"status\": \"processed\", \"records_processed\": metadata['record_count']}\n",
        "    \n",
        "    @task\n",
        "    def store_summary(summary: dict):\n",
        "        \"\"\"\n",
        "        ‚úÖ Best Practice: Only store summary/aggregated data\n",
        "        \"\"\"\n",
        "        print(f\"Storing summary: {summary}\")\n",
        "        return \"Summary stored\"\n",
        "    \n",
        "    # Workflow with best practices\n",
        "    metadata = extract_metadata_only()\n",
        "    summary = process_file(metadata)\n",
        "    store_summary(summary)\n",
        "\n",
        "# Create DAG\n",
        "xcom_best_practices_dag_instance = xcom_best_practices_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Best Practices DAG created!\")\n",
        "print(\"\\nüìã XCom Best Practices:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"‚úÖ DO:\")\n",
        "print(\"  - Ch·ªâ pass small data (< 48KB)\")\n",
        "print(\"  - Pass metadata/references thay v√¨ large datasets\")\n",
        "print(\"  - Pass file paths thay v√¨ file contents\")\n",
        "print(\"  - Pass aggregated/summary data\")\n",
        "print(\"  - S·ª≠ d·ª•ng Task SDK cho automatic XCom\")\n",
        "print(\"\\n‚ùå DON'T:\")\n",
        "print(\"  - Pass large datasets qua XCom\")\n",
        "print(\"  - Pass binary data qua XCom\")\n",
        "print(\"  - Pass sensitive data (use Variables/Connections)\")\n",
        "print(\"  - Rely on XCom cho data storage\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nüí° Alternatives cho Large Data:\")\n",
        "print(\"  - File storage (S3, GCS, local files)\")\n",
        "print(\"  - Databases\")\n",
        "print(\"  - External storage systems\")\n",
        "print(\"  - Pass only references/IDs qua XCom\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. XCom with Task Mapping and Dynamic Tasks\n",
        "\n",
        "XCom works well with dynamic task mapping - each mapped task instance has its own XCom.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAG with XCom and Task Mapping\n",
        "@dag(\n",
        "    dag_id=\"xcom_task_mapping_example\",\n",
        "    schedule=None,\n",
        "    start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
        "    catchup=False,\n",
        "    tags=[\"xcom\", \"task-mapping\"],\n",
        ")\n",
        "def xcom_task_mapping_dag():\n",
        "    \"\"\"\n",
        "    ### XCom with Task Mapping\n",
        "    XCom works with dynamic task mapping.\n",
        "    \"\"\"\n",
        "    \n",
        "    @task\n",
        "    def get_files_to_process():\n",
        "        \"\"\"Get list of files to process\"\"\"\n",
        "        files = [\n",
        "            {\"path\": \"/data/file1.csv\", \"size\": 1000},\n",
        "            {\"path\": \"/data/file2.csv\", \"size\": 2000},\n",
        "            {\"path\": \"/data/file3.csv\", \"size\": 1500},\n",
        "        ]\n",
        "        print(f\"Found {len(files)} files to process\")\n",
        "        return files\n",
        "    \n",
        "    @task\n",
        "    def process_file(file_info: dict):\n",
        "        \"\"\"Process one file - will be mapped for each file\"\"\"\n",
        "        file_path = file_info['path']\n",
        "        file_size = file_info['size']\n",
        "        \n",
        "        # Simulate processing\n",
        "        records_processed = file_size // 100\n",
        "        \n",
        "        result = {\n",
        "            \"file_path\": file_path,\n",
        "            \"records_processed\": records_processed,\n",
        "            \"status\": \"success\"\n",
        "        }\n",
        "        \n",
        "        print(f\"Processed {file_path}: {records_processed} records\")\n",
        "        return result\n",
        "    \n",
        "    @task\n",
        "    def aggregate_results(results: list):\n",
        "        \"\"\"Aggregate results from all mapped tasks\"\"\"\n",
        "        total_records = sum(r['records_processed'] for r in results)\n",
        "        total_files = len(results)\n",
        "        \n",
        "        summary = {\n",
        "            \"total_files\": total_files,\n",
        "            \"total_records\": total_records,\n",
        "            \"average_records_per_file\": total_records / total_files if total_files > 0 else 0\n",
        "        }\n",
        "        \n",
        "        print(f\"Aggregated summary: {summary}\")\n",
        "        return summary\n",
        "    \n",
        "    # Get files\n",
        "    files = get_files_to_process()\n",
        "    \n",
        "    # Process files with dynamic mapping\n",
        "    # Each mapped task instance will have its own XCom\n",
        "    processed_files = process_file.expand(file_info=files)\n",
        "    \n",
        "    # Aggregate - receives list of all results\n",
        "    aggregate_results(processed_files)\n",
        "\n",
        "# Create DAG\n",
        "xcom_task_mapping_dag_instance = xcom_task_mapping_dag()\n",
        "\n",
        "print(\"‚úÖ XCom Task Mapping DAG created!\")\n",
        "print(f\"Tasks: {[task.task_id for task in xcom_task_mapping_dag_instance.tasks]}\")\n",
        "print(\"\\nüí° XCom v·ªõi Task Mapping:\")\n",
        "print(\"  - M·ªói mapped task instance c√≥ XCom ri√™ng\")\n",
        "print(\"  - Aggregate task nh·∫≠n list c·ªßa t·∫•t c·∫£ results\")\n",
        "print(\"  - XCom key t·ª± ƒë·ªông include map index\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary and Next Steps\n",
        "\n",
        "### ‚úÖ What we learned:\n",
        "1. XCom basics - Cross-communication between tasks\n",
        "2. Task SDK automatic XCom - Automatic return values\n",
        "3. PythonOperator manual XCom - Push/pull operations\n",
        "4. Multiple return values with dictionaries\n",
        "5. Complex data structures in XCom\n",
        "6. Pull from multiple upstream tasks\n",
        "7. XCom limitations and best practices\n",
        "8. XCom with task mapping\n",
        "\n",
        "### üìö Next Lab:\n",
        "- **Lab 6**: Scheduling and Timetables\n",
        "- Cron expressions\n",
        "- Timedelta schedules\n",
        "- Custom timetables\n",
        "- Catchup and data intervals\n",
        "\n",
        "### üîó Useful Links:\n",
        "- [XCom Documentation](https://airflow.apache.org/docs/apache-airflow/3.1.1/core-concepts/xcoms.html)\n",
        "- [Task SDK XCom](https://airflow.apache.org/docs/apache-airflow/3.1.1/task-sdk/index.html)\n",
        "- [XCom Best Practices](https://airflow.apache.org/docs/apache-airflow/3.1.1/best-practices.html#xcom)\n",
        "\n",
        "### üí° Key Takeaways:\n",
        "\n",
        "**XCom Size Limits:**\n",
        "- Default: 48KB per value\n",
        "- Configurable via `xcom_max_value_size`\n",
        "- Should not pass large data\n",
        "\n",
        "**Best Practices:**\n",
        "- ‚úÖ Pass metadata/references\n",
        "- ‚úÖ Pass file paths instead of contents\n",
        "- ‚úÖ Use Task SDK for automatic XCom\n",
        "- ‚ùå Don't pass large datasets\n",
        "- ‚ùå Don't use XCom as database\n",
        "\n",
        "**Alternatives:**\n",
        "- File storage (S3, GCS, local)\n",
        "- Databases\n",
        "- External APIs\n",
        "- Airflow Variables (for config)\n",
        "\n",
        "### üí° Exercises:\n",
        "1. Create DAG with XCom passing metadata between tasks\n",
        "2. Implement data pipeline with file paths via XCom\n",
        "3. Use multiple return values\n",
        "4. Combine XCom with task mapping\n",
        "5. Implement error handling with XCom\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
