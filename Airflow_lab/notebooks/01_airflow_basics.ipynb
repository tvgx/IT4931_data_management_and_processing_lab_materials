{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1: Airflow Basics - Introduction to Apache Airflow\n",
        "\n",
        "## üéØ Objectives\n",
        "- Understand the architecture and components of Apache Airflow\n",
        "- Learn how to use Airflow Web UI\n",
        "- Get familiar with Airflow CLI commands\n",
        "- Create and run your first DAG\n",
        "\n",
        "## üìã Prerequisites\n",
        "- Airflow cluster is running (`docker compose up -d`)\n",
        "- Access to Airflow UI at http://localhost:8080\n",
        "- Basic understanding of Python and workflows\n",
        "\n",
        "## üèóÔ∏è Airflow Architecture Overview\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Web UI     ‚îÇ  Port 8080 - Manage and monitor DAGs\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "      ‚îÇ\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Scheduler  ‚îÇ  Schedule and trigger tasks\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "      ‚îÇ\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Executor   ‚îÇ  Execute tasks (LocalExecutor)\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "      ‚îÇ\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Metadata   ‚îÇ  PostgreSQL - Store metadata\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "## üìö Key Concepts\n",
        "- **DAG (Directed Acyclic Graph)**: Workflow defined in Python\n",
        "- **Task**: Smallest unit of work in a DAG\n",
        "- **Operator**: Template for a task (BashOperator, PythonOperator, etc.)\n",
        "- **Scheduler**: Component that schedules and triggers DAG runs\n",
        "- **Executor**: Component that executes tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Check Airflow Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check Airflow version and connection\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Check Airflow CLI\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        [\"docker\", \"compose\", \"exec\", \"-T\", \"airflow-webserver\", \"airflow\", \"version\"],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        timeout=10\n",
        "    )\n",
        "    print(\"‚úÖ Airflow CLI accessible\")\n",
        "    print(result.stdout)\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Airflow CLI check failed: {e}\")\n",
        "    print(\"üí° Make sure Airflow is running: docker compose up -d\")\n",
        "\n",
        "# Check Airflow UI\n",
        "try:\n",
        "    response = requests.get(\"http://localhost:8080/health\", timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        print(\"\\n‚úÖ Airflow Web UI is accessible at http://localhost:8080\")\n",
        "        print(f\"   Health check: {response.json()}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è  Airflow UI returned status code: {response.status_code}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è  Cannot connect to Airflow UI: {e}\")\n",
        "    print(\"üí° Make sure Airflow webserver is running: docker compose up -d\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. List DAGs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all DAGs\n",
        "result = subprocess.run(\n",
        "    [\"docker\", \"compose\", \"exec\", \"-T\", \"airflow-webserver\", \"airflow\", \"dags\", \"list\"],\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        "    timeout=10\n",
        ")\n",
        "\n",
        "print(\"üìã Available DAGs:\")\n",
        "print(\"=\" * 60)\n",
        "print(result.stdout)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Parse and display DAGs\n",
        "lines = result.stdout.strip().split('\\n')\n",
        "dag_list = []\n",
        "for line in lines[2:]:  # Skip header lines\n",
        "    if line.strip():\n",
        "        parts = line.split()\n",
        "        if len(parts) >= 2:\n",
        "            dag_list.append({\n",
        "                'dag_id': parts[0],\n",
        "                'owner': parts[1] if len(parts) > 1 else 'N/A',\n",
        "                'status': parts[-1] if len(parts) > 2 else 'N/A'\n",
        "            })\n",
        "\n",
        "if dag_list:\n",
        "    print(f\"\\n‚úÖ Found {len(dag_list)} DAG(s):\")\n",
        "    for dag in dag_list:\n",
        "        print(f\"   - {dag['dag_id']} (Owner: {dag['owner']})\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No DAGs found. Make sure DAGs are in the dags/ directory.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. View DAG Details\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View details of hello_world DAG\n",
        "dag_id = \"hello_world\"\n",
        "\n",
        "print(f\"üìä DAG Details: {dag_id}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Show DAG structure\n",
        "result = subprocess.run(\n",
        "    [\"docker\", \"compose\", \"exec\", \"-T\", \"airflow-webserver\", \"airflow\", \"dags\", \"show\", dag_id],\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        "    timeout=10\n",
        ")\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(result.stdout)\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  DAG '{dag_id}' not found or error occurred\")\n",
        "    print(result.stderr)\n",
        "    print(\"\\nüí° Available DAGs:\")\n",
        "    subprocess.run(\n",
        "        [\"docker\", \"compose\", \"exec\", \"-T\", \"airflow-webserver\", \"airflow\", \"dags\", \"list\"],\n",
        "        timeout=10\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Using Airflow REST API\n",
        "\n",
        "Airflow provides REST API for programmatic interaction. We will use the API to:\n",
        "- Get DAG information\n",
        "- Trigger DAG runs\n",
        "- View task status\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure Airflow API\n",
        "AIRFLOW_URL = \"http://localhost:8080\"\n",
        "AIRFLOW_USERNAME = \"airflow\"\n",
        "AIRFLOW_PASSWORD = \"airflow\"\n",
        "\n",
        "# Helper function to call API\n",
        "def airflow_api_call(endpoint, method=\"GET\", data=None):\n",
        "    \"\"\"Call Airflow REST API\"\"\"\n",
        "    url = f\"{AIRFLOW_URL}/api/v1/{endpoint}\"\n",
        "    auth = (AIRFLOW_USERNAME, AIRFLOW_PASSWORD)\n",
        "    \n",
        "    try:\n",
        "        if method == \"GET\":\n",
        "            response = requests.get(url, auth=auth, timeout=10)\n",
        "        elif method == \"POST\":\n",
        "            response = requests.post(url, auth=auth, json=data, timeout=10)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported method: {method}\")\n",
        "        \n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå API call failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# Get list of DAGs from API\n",
        "print(\"üìã Getting DAGs from REST API...\")\n",
        "dag_list_response = airflow_api_call(\"dags\")\n",
        "\n",
        "if dag_list_response:\n",
        "    dags = dag_list_response.get(\"dags\", [])\n",
        "    print(f\"\\n‚úÖ Found {len(dags)} DAG(s) via API:\")\n",
        "    for dag in dags[:10]:  # Show first 10\n",
        "        print(f\"   - {dag['dag_id']} (Is Paused: {dag.get('is_paused', False)})\")\n",
        "    \n",
        "    if len(dags) > 10:\n",
        "        print(f\"   ... and {len(dags) - 10} more\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Trigger DAG Run\n",
        "\n",
        "We can trigger a DAG run through REST API or CLI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trigger DAG run via REST API\n",
        "dag_id = \"hello_world\"\n",
        "\n",
        "print(f\"üöÄ Triggering DAG: {dag_id}\")\n",
        "\n",
        "# Trigger DAG\n",
        "trigger_response = airflow_api_call(\n",
        "    f\"dags/{dag_id}/dagRuns\",\n",
        "    method=\"POST\",\n",
        "    data={\n",
        "        \"dag_run_id\": f\"manual_run_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}\",\n",
        "        \"conf\": {}\n",
        "    }\n",
        ")\n",
        "\n",
        "if trigger_response:\n",
        "    print(f\"‚úÖ DAG run triggered successfully!\")\n",
        "    print(f\"   DAG Run ID: {trigger_response.get('dag_run_id')}\")\n",
        "    print(f\"   State: {trigger_response.get('state')}\")\n",
        "    print(f\"\\nüí° Check the Airflow UI to see the DAG run: http://localhost:8080\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Failed to trigger DAG run\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. View DAG Runs and Task Status\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "dag_id = \"hello_world\"\n",
        "\n",
        "# Wait a bit for DAG run to be created\n",
        "print(\"‚è≥ Waiting for DAG run to be created...\")\n",
        "time.sleep(2)\n",
        "\n",
        "# Get list of DAG runs\n",
        "print(f\"\\nüìä Getting DAG runs for: {dag_id}\")\n",
        "dag_runs_response = airflow_api_call(f\"dags/{dag_id}/dagRuns?limit=5\")\n",
        "\n",
        "if dag_runs_response:\n",
        "    dag_runs = dag_runs_response.get(\"dag_runs\", [])\n",
        "    \n",
        "    if dag_runs:\n",
        "        print(f\"\\n‚úÖ Found {len(dag_runs)} DAG run(s):\")\n",
        "        print(\"=\" * 80)\n",
        "        \n",
        "        for run in dag_runs:\n",
        "            print(f\"\\nDAG Run ID: {run.get('dag_run_id')}\")\n",
        "            print(f\"  State: {run.get('state')}\")\n",
        "            print(f\"  Start Date: {run.get('start_date')}\")\n",
        "            print(f\"  End Date: {run.get('end_date', 'N/A')}\")\n",
        "            print(f\"  Duration: {run.get('duration', 'N/A')} seconds\")\n",
        "        \n",
        "        # Get task instances for the latest DAG run\n",
        "        latest_run_id = dag_runs[0]['dag_run_id']\n",
        "        print(f\"\\nüìã Task instances for DAG run: {latest_run_id}\")\n",
        "        \n",
        "        tasks_response = airflow_api_call(\n",
        "            f\"dags/{dag_id}/dagRuns/{latest_run_id}/taskInstances\"\n",
        "        )\n",
        "        \n",
        "        if tasks_response:\n",
        "            tasks = tasks_response.get(\"task_instances\", [])\n",
        "            print(f\"\\n‚úÖ Found {len(tasks)} task instance(s):\")\n",
        "            for task in tasks:\n",
        "                print(f\"   - {task.get('task_id')}: {task.get('state')}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No DAG runs found\")\n",
        "        print(\"üí° Trigger a DAG run first or wait for scheduled runs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary and Next Steps\n",
        "\n",
        "### ‚úÖ What we learned:\n",
        "1. Basic Airflow architecture\n",
        "2. How to use Airflow CLI\n",
        "3. How to use Airflow REST API\n",
        "4. How to trigger and monitor DAG runs\n",
        "\n",
        "### üìö Next Lab:\n",
        "- **Lab 2**: DAGs and Tasks - Learn how to create DAGs with Task SDK\n",
        "- Create DAGs with @dag and @task decorators\n",
        "- Define task dependencies\n",
        "- Handle errors and retries\n",
        "\n",
        "### üîó Useful Links:\n",
        "- [Airflow Documentation](https://airflow.apache.org/docs/apache-airflow/3.1.1/)\n",
        "- [Airflow Task SDK](https://airflow.apache.org/docs/apache-airflow/3.1.1/task-sdk/index.html)\n",
        "- [Airflow REST API](https://airflow.apache.org/docs/apache-airflow/3.1.1/stable-rest-api-ref.html)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
