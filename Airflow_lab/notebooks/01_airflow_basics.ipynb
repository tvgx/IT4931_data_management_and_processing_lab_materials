{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1: Airflow Basics - Gi·ªõi thi·ªáu Apache Airflow\n",
        "\n",
        "## üéØ Objectives\n",
        "- Hi·ªÉu ki·∫øn tr√∫c v√† components c·ªßa Apache Airflow\n",
        "- H·ªçc c√°ch s·ª≠ d·ª•ng Airflow Web UI\n",
        "- L√†m quen v·ªõi Airflow CLI commands\n",
        "- T·∫°o v√† ch·∫°y DAG ƒë·∫ßu ti√™n\n",
        "\n",
        "## üìã Prerequisites\n",
        "- Airflow cluster ƒëang ch·∫°y (`docker compose up -d`)\n",
        "- Truy c·∫≠p ƒë∆∞·ª£c Airflow UI t·∫°i http://localhost:8080\n",
        "- Basic understanding c·ªßa Python v√† workflows\n",
        "\n",
        "## üèóÔ∏è Airflow Architecture Overview\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Web UI     ‚îÇ  Port 8080 - Qu·∫£n l√Ω v√† gi√°m s√°t DAGs\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "      ‚îÇ\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Scheduler  ‚îÇ  L·∫≠p l·ªãch v√† trigger tasks\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "      ‚îÇ\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Executor   ‚îÇ  Th·ª±c thi tasks (LocalExecutor)\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "      ‚îÇ\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Metadata   ‚îÇ  PostgreSQL - L∆∞u tr·ªØ metadata\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "## üìö Key Concepts\n",
        "- **DAG (Directed Acyclic Graph)**: Workflow ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a b·∫±ng Python\n",
        "- **Task**: ƒê∆°n v·ªã c√¥ng vi·ªác nh·ªè nh·∫•t trong DAG\n",
        "- **Operator**: Template cho m·ªôt task (BashOperator, PythonOperator, etc.)\n",
        "- **Scheduler**: Component l·∫≠p l·ªãch v√† trigger DAG runs\n",
        "- **Executor**: Component th·ª±c thi tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Ki·ªÉm tra Airflow Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ki·ªÉm tra Airflow version v√† connection\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Ki·ªÉm tra Airflow CLI\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        [\"docker\", \"compose\", \"exec\", \"-T\", \"airflow-webserver\", \"airflow\", \"version\"],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        timeout=10\n",
        "    )\n",
        "    print(\"‚úÖ Airflow CLI accessible\")\n",
        "    print(result.stdout)\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Airflow CLI check failed: {e}\")\n",
        "    print(\"üí° Make sure Airflow is running: docker compose up -d\")\n",
        "\n",
        "# Ki·ªÉm tra Airflow UI\n",
        "try:\n",
        "    response = requests.get(\"http://localhost:8080/health\", timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        print(\"\\n‚úÖ Airflow Web UI is accessible at http://localhost:8080\")\n",
        "        print(f\"   Health check: {response.json()}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è  Airflow UI returned status code: {response.status_code}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è  Cannot connect to Airflow UI: {e}\")\n",
        "    print(\"üí° Make sure Airflow webserver is running: docker compose up -d\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Li·ªát k√™ DAGs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Li·ªát k√™ t·∫•t c·∫£ DAGs\n",
        "result = subprocess.run(\n",
        "    [\"docker\", \"compose\", \"exec\", \"-T\", \"airflow-webserver\", \"airflow\", \"dags\", \"list\"],\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        "    timeout=10\n",
        ")\n",
        "\n",
        "print(\"üìã Available DAGs:\")\n",
        "print(\"=\" * 60)\n",
        "print(result.stdout)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Parse v√† hi·ªÉn th·ªã DAGs\n",
        "lines = result.stdout.strip().split('\\n')\n",
        "dag_list = []\n",
        "for line in lines[2:]:  # Skip header lines\n",
        "    if line.strip():\n",
        "        parts = line.split()\n",
        "        if len(parts) >= 2:\n",
        "            dag_list.append({\n",
        "                'dag_id': parts[0],\n",
        "                'owner': parts[1] if len(parts) > 1 else 'N/A',\n",
        "                'status': parts[-1] if len(parts) > 2 else 'N/A'\n",
        "            })\n",
        "\n",
        "if dag_list:\n",
        "    print(f\"\\n‚úÖ Found {len(dag_list)} DAG(s):\")\n",
        "    for dag in dag_list:\n",
        "        print(f\"   - {dag['dag_id']} (Owner: {dag['owner']})\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No DAGs found. Make sure DAGs are in the dags/ directory.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Xem chi ti·∫øt m·ªôt DAG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Xem chi ti·∫øt DAG hello_world\n",
        "dag_id = \"hello_world\"\n",
        "\n",
        "print(f\"üìä DAG Details: {dag_id}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Show DAG structure\n",
        "result = subprocess.run(\n",
        "    [\"docker\", \"compose\", \"exec\", \"-T\", \"airflow-webserver\", \"airflow\", \"dags\", \"show\", dag_id],\n",
        "    capture_output=True,\n",
        "    text=True,\n",
        "    timeout=10\n",
        ")\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(result.stdout)\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  DAG '{dag_id}' not found or error occurred\")\n",
        "    print(result.stderr)\n",
        "    print(\"\\nüí° Available DAGs:\")\n",
        "    subprocess.run(\n",
        "        [\"docker\", \"compose\", \"exec\", \"-T\", \"airflow-webserver\", \"airflow\", \"dags\", \"list\"],\n",
        "        timeout=10\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. S·ª≠ d·ª•ng Airflow REST API\n",
        "\n",
        "Airflow cung c·∫•p REST API ƒë·ªÉ t∆∞∆°ng t√°c programmatically. Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng API ƒë·ªÉ:\n",
        "- L·∫•y th√¥ng tin DAGs\n",
        "- Trigger DAG runs\n",
        "- Xem task status\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C·∫•u h√¨nh Airflow API\n",
        "AIRFLOW_URL = \"http://localhost:8080\"\n",
        "AIRFLOW_USERNAME = \"airflow\"\n",
        "AIRFLOW_PASSWORD = \"airflow\"\n",
        "\n",
        "# Helper function ƒë·ªÉ g·ªçi API\n",
        "def airflow_api_call(endpoint, method=\"GET\", data=None):\n",
        "    \"\"\"G·ªçi Airflow REST API\"\"\"\n",
        "    url = f\"{AIRFLOW_URL}/api/v1/{endpoint}\"\n",
        "    auth = (AIRFLOW_USERNAME, AIRFLOW_PASSWORD)\n",
        "    \n",
        "    try:\n",
        "        if method == \"GET\":\n",
        "            response = requests.get(url, auth=auth, timeout=10)\n",
        "        elif method == \"POST\":\n",
        "            response = requests.post(url, auth=auth, json=data, timeout=10)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported method: {method}\")\n",
        "        \n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå API call failed: {e}\")\n",
        "        return None\n",
        "\n",
        "# L·∫•y danh s√°ch DAGs t·ª´ API\n",
        "print(\"üìã Getting DAGs from REST API...\")\n",
        "dag_list_response = airflow_api_call(\"dags\")\n",
        "\n",
        "if dag_list_response:\n",
        "    dags = dag_list_response.get(\"dags\", [])\n",
        "    print(f\"\\n‚úÖ Found {len(dags)} DAG(s) via API:\")\n",
        "    for dag in dags[:10]:  # Show first 10\n",
        "        print(f\"   - {dag['dag_id']} (Is Paused: {dag.get('is_paused', False)})\")\n",
        "    \n",
        "    if len(dags) > 10:\n",
        "        print(f\"   ... and {len(dags) - 10} more\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Trigger DAG Run\n",
        "\n",
        "Ch√∫ng ta c√≥ th·ªÉ trigger m·ªôt DAG run th√¥ng qua REST API ho·∫∑c CLI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trigger DAG run qua REST API\n",
        "dag_id = \"hello_world\"\n",
        "\n",
        "print(f\"üöÄ Triggering DAG: {dag_id}\")\n",
        "\n",
        "# Trigger DAG\n",
        "trigger_response = airflow_api_call(\n",
        "    f\"dags/{dag_id}/dagRuns\",\n",
        "    method=\"POST\",\n",
        "    data={\n",
        "        \"dag_run_id\": f\"manual_run_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}\",\n",
        "        \"conf\": {}\n",
        "    }\n",
        ")\n",
        "\n",
        "if trigger_response:\n",
        "    print(f\"‚úÖ DAG run triggered successfully!\")\n",
        "    print(f\"   DAG Run ID: {trigger_response.get('dag_run_id')}\")\n",
        "    print(f\"   State: {trigger_response.get('state')}\")\n",
        "    print(f\"\\nüí° Check the Airflow UI to see the DAG run: http://localhost:8080\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Failed to trigger DAG run\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Xem DAG Runs v√† Task Status\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "dag_id = \"hello_world\"\n",
        "\n",
        "# ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ DAG run ƒë∆∞·ª£c t·∫°o\n",
        "print(\"‚è≥ Waiting for DAG run to be created...\")\n",
        "time.sleep(2)\n",
        "\n",
        "# L·∫•y danh s√°ch DAG runs\n",
        "print(f\"\\nüìä Getting DAG runs for: {dag_id}\")\n",
        "dag_runs_response = airflow_api_call(f\"dags/{dag_id}/dagRuns?limit=5\")\n",
        "\n",
        "if dag_runs_response:\n",
        "    dag_runs = dag_runs_response.get(\"dag_runs\", [])\n",
        "    \n",
        "    if dag_runs:\n",
        "        print(f\"\\n‚úÖ Found {len(dag_runs)} DAG run(s):\")\n",
        "        print(\"=\" * 80)\n",
        "        \n",
        "        for run in dag_runs:\n",
        "            print(f\"\\nDAG Run ID: {run.get('dag_run_id')}\")\n",
        "            print(f\"  State: {run.get('state')}\")\n",
        "            print(f\"  Start Date: {run.get('start_date')}\")\n",
        "            print(f\"  End Date: {run.get('end_date', 'N/A')}\")\n",
        "            print(f\"  Duration: {run.get('duration', 'N/A')} seconds\")\n",
        "        \n",
        "        # L·∫•y task instances cho DAG run m·ªõi nh·∫•t\n",
        "        latest_run_id = dag_runs[0]['dag_run_id']\n",
        "        print(f\"\\nüìã Task instances for DAG run: {latest_run_id}\")\n",
        "        \n",
        "        tasks_response = airflow_api_call(\n",
        "            f\"dags/{dag_id}/dagRuns/{latest_run_id}/taskInstances\"\n",
        "        )\n",
        "        \n",
        "        if tasks_response:\n",
        "            tasks = tasks_response.get(\"task_instances\", [])\n",
        "            print(f\"\\n‚úÖ Found {len(tasks)} task instance(s):\")\n",
        "            for task in tasks:\n",
        "                print(f\"   - {task.get('task_id')}: {task.get('state')}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No DAG runs found\")\n",
        "        print(\"üí° Trigger a DAG run first or wait for scheduled runs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. T√≥m t·∫Øt v√† Next Steps\n",
        "\n",
        "### ‚úÖ Nh·ªØng g√¨ ƒë√£ h·ªçc:\n",
        "1. Ki·∫øn tr√∫c c∆° b·∫£n c·ªßa Airflow\n",
        "2. C√°ch s·ª≠ d·ª•ng Airflow CLI\n",
        "3. C√°ch s·ª≠ d·ª•ng Airflow REST API\n",
        "4. C√°ch trigger v√† monitor DAG runs\n",
        "\n",
        "### üìö Next Lab:\n",
        "- **Lab 2**: DAGs v√† Tasks - H·ªçc c√°ch t·∫°o DAGs v·ªõi Task SDK\n",
        "- T·∫°o DAGs v·ªõi @dag v√† @task decorators\n",
        "- ƒê·ªãnh nghƒ©a task dependencies\n",
        "- X·ª≠ l√Ω errors v√† retries\n",
        "\n",
        "### üîó Useful Links:\n",
        "- [Airflow Documentation](https://airflow.apache.org/docs/apache-airflow/3.1.1/)\n",
        "- [Airflow Task SDK](https://airflow.apache.org/docs/apache-airflow/3.1.1/task-sdk/index.html)\n",
        "- [Airflow REST API](https://airflow.apache.org/docs/apache-airflow/3.1.1/stable-rest-api-ref.html)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
