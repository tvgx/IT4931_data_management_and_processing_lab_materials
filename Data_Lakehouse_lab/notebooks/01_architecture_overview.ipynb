{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1: Data Lakehouse Architecture Overview\n",
        "\n",
        "## ğŸ¯ Objectives\n",
        "- Hiá»ƒu Data Lakehouse architecture\n",
        "- Tá»•ng quan vá» technology stack\n",
        "- Integration patterns giá»¯a cÃ¡c components\n",
        "- Best practices cho data lakehouse\n",
        "\n",
        "## ğŸ“‹ Prerequisites\n",
        "- HoÃ n thÃ nh cÃ¡c labs trÆ°á»›c:\n",
        "  - Kafka Lab\n",
        "  - Spark Lab\n",
        "  - Airflow Lab\n",
        "  - dbt Lab\n",
        "  - Great Expectations Lab\n",
        "  - PyIceberg Lab\n",
        "\n",
        "## ğŸ—ï¸ Data Lakehouse Architecture\n",
        "\n",
        "**Data Lakehouse** káº¿t há»£p:\n",
        "- **Data Lake**: Storage cho raw data (Iceberg)\n",
        "- **Data Warehouse**: Structured analytics (dbt marts)\n",
        "- **Stream Processing**: Real-time data (Kafka + Spark)\n",
        "- **Orchestration**: Workflow management (Airflow)\n",
        "- **Data Quality**: Validation (Great Expectations)\n",
        "\n",
        "### Complete Architecture:\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ Data Sourcesâ”‚  APIs, Databases, Files, Streams\n",
        "â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
        "       â”‚\n",
        "       â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚    Kafka    â”‚â”€â”€â”€â”€â–¶â”‚ Spark Stream â”‚  Real-time ingestion\n",
        "â”‚  (Ingest)   â”‚     â”‚  Processing  â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                           â”‚\n",
        "                           â–¼\n",
        "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚   Iceberg   â”‚  Data Lakehouse Storage\n",
        "                    â”‚   Tables    â”‚  (ACID, Time Travel)\n",
        "                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                           â”‚\n",
        "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "        â”‚                  â”‚                  â”‚\n",
        "        â–¼                  â–¼                  â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚     dbt     â”‚   â”‚      GE      â”‚   â”‚   Spark     â”‚\n",
        "â”‚(Transform)  â”‚   â”‚  (Quality)   â”‚   â”‚  (Batch)    â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
        "       â”‚                  â”‚                  â”‚\n",
        "       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                           â”‚\n",
        "                           â–¼\n",
        "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚   Airflow   â”‚  Orchestration\n",
        "                    â”‚  (Orchestr) â”‚\n",
        "                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                           â”‚\n",
        "                           â–¼\n",
        "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                    â”‚  Analytics  â”‚  BI, Reports, ML\n",
        "                    â”‚   Layer     â”‚\n",
        "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Technology Stack Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ğŸ—ï¸ Data Lakehouse Technology Stack:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\"\"\n",
        "1. Apache Kafka\n",
        "   - Role: Real-time data ingestion\n",
        "   - Use Case: Stream data tá»« multiple sources\n",
        "   - Integration: Kafka â†’ Spark Streaming\n",
        "\n",
        "2. Apache Spark\n",
        "   - Role: Big data processing\n",
        "   - Use Case: Batch vÃ  streaming processing\n",
        "   - Integration: Spark â†’ Iceberg (write), Spark â†’ dbt (read)\n",
        "\n",
        "3. Apache Iceberg\n",
        "   - Role: Data lakehouse storage format\n",
        "   - Use Case: ACID transactions, time travel, schema evolution\n",
        "   - Integration: Spark writes to Iceberg, dbt reads from Iceberg\n",
        "\n",
        "4. dbt (Data Build Tool)\n",
        "   - Role: Data transformations\n",
        "   - Use Case: Transform data trong data warehouse\n",
        "   - Integration: dbt reads Iceberg tables, creates marts\n",
        "\n",
        "5. Great Expectations\n",
        "   - Role: Data quality vÃ  validation\n",
        "   - Use Case: Validate data á»Ÿ má»i stage\n",
        "   - Integration: GE validates dbt outputs, raw data\n",
        "\n",
        "6. Apache Airflow\n",
        "   - Role: Workflow orchestration\n",
        "   - Use Case: Schedule vÃ  orchestrate entire pipeline\n",
        "   - Integration: Orchestrates táº¥t cáº£ components\n",
        "\"\"\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Flow trong Lakehouse\n",
        "\n",
        "Luá»“ng data tá»« ingestion Ä‘áº¿n analytics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ğŸ“Š Data Flow trong Data Lakehouse:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\"\"\n",
        "Stage 1: Ingestion (Kafka)\n",
        "  - Data sources â†’ Kafka topics\n",
        "  - Schema validation\n",
        "  - Data quality checks\n",
        "\n",
        "Stage 2: Processing (Spark Streaming)\n",
        "  - Kafka â†’ Spark Structured Streaming\n",
        "  - Real-time transformations\n",
        "  - Write to Iceberg tables (Bronze layer)\n",
        "\n",
        "Stage 3: Storage (Iceberg)\n",
        "  - Bronze: Raw data\n",
        "  - Silver: Cleaned data\n",
        "  - Gold: Aggregated data\n",
        "\n",
        "Stage 4: Transformation (dbt)\n",
        "  - Read tá»« Iceberg Silver/Gold\n",
        "  - Business logic transformations\n",
        "  - Create marts tables\n",
        "\n",
        "Stage 5: Quality (Great Expectations)\n",
        "  - Validate raw data (Bronze)\n",
        "  - Validate transformed data (dbt outputs)\n",
        "  - Data quality monitoring\n",
        "\n",
        "Stage 6: Orchestration (Airflow)\n",
        "  - Schedule entire pipeline\n",
        "  - Manage dependencies\n",
        "  - Error handling vÃ  retries\n",
        "\n",
        "Stage 7: Analytics\n",
        "  - BI tools query marts\n",
        "  - ML models train on data\n",
        "  - Reports vÃ  dashboards\n",
        "\"\"\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Best Practices\n",
        "\n",
        "Best practices cho Data Lakehouse architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"âœ… Data Lakehouse Best Practices:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\"\"\n",
        "1. **Data Layers (Medallion Architecture):**\n",
        "   - Bronze: Raw data (as-is from sources)\n",
        "   - Silver: Cleaned vÃ  validated data\n",
        "   - Gold: Business-level aggregated data\n",
        "\n",
        "2. **Schema Management:**\n",
        "   - Use Iceberg schema evolution\n",
        "   - Version control schemas\n",
        "   - Document schema changes\n",
        "\n",
        "3. **Data Quality:**\n",
        "   - Validate at ingestion (Bronze)\n",
        "   - Validate after transformation (Silver/Gold)\n",
        "   - Monitor data quality metrics\n",
        "\n",
        "4. **Orchestration:**\n",
        "   - Use Airflow cho workflow management\n",
        "   - Implement proper error handling\n",
        "   - Set up monitoring vÃ  alerting\n",
        "\n",
        "5. **Performance:**\n",
        "   - Partition data appropriately\n",
        "   - Use columnar formats (Parquet)\n",
        "   - Optimize Spark jobs\n",
        "   - Cache frequently used data\n",
        "\n",
        "6. **Security:**\n",
        "   - Implement access controls\n",
        "   - Encrypt sensitive data\n",
        "   - Audit data access\n",
        "   - Use secure connections\n",
        "\n",
        "7. **Monitoring:**\n",
        "   - Track pipeline health\n",
        "   - Monitor data quality\n",
        "   - Alert on failures\n",
        "   - Track performance metrics\n",
        "\"\"\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. TÃ³m táº¯t vÃ  Next Steps\n",
        "\n",
        "### âœ… Nhá»¯ng gÃ¬ Ä‘Ã£ há»c:\n",
        "1. Data Lakehouse architecture\n",
        "2. Technology stack vÃ  roles\n",
        "3. Data flow trong lakehouse\n",
        "4. Best practices\n",
        "\n",
        "### ğŸ“š Next Lab:\n",
        "- **Lab 2**: Data Ingestion vá»›i Kafka\n",
        "- Ingest data tá»« multiple sources\n",
        "- Kafka producers vÃ  consumers\n",
        "- Schema validation\n",
        "\n",
        "### ğŸ’¡ Key Takeaways:\n",
        "\n",
        "**Data Lakehouse:**\n",
        "- Combines data lake vÃ  data warehouse\n",
        "- ACID transactions vá»›i Iceberg\n",
        "- Real-time vÃ  batch processing\n",
        "- Complete data platform\n",
        "\n",
        "**Technology Stack:**\n",
        "- Kafka: Ingestion\n",
        "- Spark: Processing\n",
        "- Iceberg: Storage\n",
        "- dbt: Transformation\n",
        "- GE: Quality\n",
        "- Airflow: Orchestration\n",
        "\n",
        "### ğŸ”— Useful Links:\n",
        "- [Data Lakehouse Architecture](https://www.databricks.com/glossary/data-lakehouse)\n",
        "- [Iceberg Documentation](https://iceberg.apache.org/)\n",
        "- [dbt Best Practices](https://docs.getdbt.com/guides/best-practices)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
