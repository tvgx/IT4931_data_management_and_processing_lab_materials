# Big Data Engineering - Course Materials

## ğŸ“‹ Overview

Repository nÃ y chá»©a toÃ n bá»™ tÃ i liá»‡u vÃ  bÃ i lab cho khÃ³a há»c **Big Data Engineering**, bao gá»“m cÃ¡c cÃ´ng nghá»‡ vÃ  cÃ´ng cá»¥ hiá»‡n Ä‘áº¡i trong Data Engineering stack. Táº¥t cáº£ cÃ¡c labs Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ há»c viÃªn cÃ³ thá»ƒ thá»±c hÃ nh tá»« cÆ¡ báº£n Ä‘áº¿n nÃ¢ng cao vá»›i cÃ¡c use cases thá»±c táº¿.

## ğŸ¯ Learning Objectives

Sau khi hoÃ n thÃ nh cÃ¡c labs trong repository nÃ y, há»c viÃªn sáº½ cÃ³ thá»ƒ:

- âœ… Hiá»ƒu vÃ  sá»­ dá»¥ng cÃ¡c cÃ´ng nghá»‡ Big Data phá»• biáº¿n
- âœ… XÃ¢y dá»±ng data pipelines end-to-end
- âœ… Xá»­ lÃ½ real-time vÃ  batch data processing
- âœ… Quáº£n lÃ½ data quality vÃ  orchestration
- âœ… Thiáº¿t káº¿ vÃ  implement data lakehouse architecture
- âœ… LÃ m viá»‡c vá»›i NoSQL databases vÃ  data formats

## ğŸ“š Lab Structure

Repository Ä‘Æ°á»£c tá»• chá»©c thÃ nh cÃ¡c labs Ä‘á»™c láº­p, má»—i lab táº­p trung vÃ o má»™t cÃ´ng nghá»‡ cá»¥ thá»ƒ:

### ğŸ”´ Core Labs (Báº¯t buá»™c)

#### 1. **Kafka Lab** - Real-time Data Streaming
- **Má»¥c tiÃªu**: Apache Kafka fundamentals vá»›i stock market data
- **Ná»™i dung**: Topics, partitions, consumer groups, offset management, real-time analytics
- **Sá»‘ notebooks**: 5 labs
- **Tech Stack**: Kafka, Zookeeper, Schema Registry, Kafka Connect, AKHQ, Redis
- **ğŸ“ ThÆ° má»¥c**: `Kafka_lab/`

#### 2. **Spark Lab** - Big Data Processing
- **Má»¥c tiÃªu**: Apache Spark cho batch vÃ  streaming processing
- **Ná»™i dung**: DataFrames, Structured Streaming, MLlib
- **Sá»‘ notebooks**: 3+ notebooks
- **Tech Stack**: Spark, Spark SQL, Structured Streaming
- **ğŸ“ ThÆ° má»¥c**: `Spark_lab/`

#### 3. **Airflow Lab** - Workflow Orchestration
- **Má»¥c tiÃªu**: Apache Airflow 3.1.1 cho data pipeline orchestration
- **Ná»™i dung**: DAGs, Tasks, Operators, Hooks, XCom, Scheduling, Integration
- **Sá»‘ notebooks**: 7 labs
- **Tech Stack**: Airflow 3.1.1, PostgreSQL, Redis, Celery
- **ğŸ“ ThÆ° má»¥c**: `Airflow_lab/`

### ğŸŸ¡ Data Transformation & Quality Labs

#### 4. **dbt Lab** - Data Transformation
- **Má»¥c tiÃªu**: dbt (Data Build Tool) cho data transformations
- **Ná»™i dung**: Models, Jinja templating, Testing, Documentation, Macros, Airflow integration
- **Sá»‘ notebooks**: 5 labs
- **Tech Stack**: dbt-core, dbt-postgres, PostgreSQL
- **ğŸ“ ThÆ° má»¥c**: `dbt_lab/`

#### 5. **Great Expectations Lab** - Data Quality
- **Má»¥c tiÃªu**: Great Expectations cho data validation vÃ  quality checks
- **Ná»™i dung**: Expectations, Checkpoints, Data Docs, dbt integration, Airflow integration
- **Sá»‘ notebooks**: 6 labs
- **Tech Stack**: Great Expectations, PostgreSQL, dbt-expectations
- **ğŸ“ ThÆ° má»¥c**: `Great_Expectations_lab/`

### ğŸŸ¢ Data Storage & Lakehouse Labs

#### 6. **PyIceberg Lab** - Data Lakehouse Format
- **Má»¥c tiÃªu**: Apache Iceberg cho data lakehouse storage
- **Ná»™i dung**: Schema evolution, Data partitioning, Compaction, Time travel
- **Sá»‘ notebooks**: 5 labs
- **Tech Stack**: PyIceberg, Apache Iceberg
- **ğŸ“ ThÆ° má»¥c**: `pyiceberg/`

#### 7. **NoSQL Lab** - Multi-model Databases
- **Má»¥c tiÃªu**: CÃ¡c loáº¡i NoSQL databases phá»• biáº¿n
- **Ná»™i dung**: MongoDB (Document), Neo4j (Graph), Redis (Key-Value), Trino (SQL on everything)
- **Sá»‘ notebooks**: 6 labs
- **Tech Stack**: MongoDB, Neo4j, Redis, Trino, PostgreSQL
- **ğŸ“ ThÆ° má»¥c**: `NoSQL_lab/`

### ğŸ”µ Integration Lab (Tá»•ng há»£p)

#### 8. **Data Lakehouse Lab** - End-to-End Integration
- **Má»¥c tiÃªu**: TÃ­ch há»£p táº¥t cáº£ cÃ¡c cÃ´ng nghá»‡ trong má»™t pipeline hoÃ n chá»‰nh
- **Ná»™i dung**: Complete data lakehouse architecture tá»« ingestion Ä‘áº¿n analytics
- **Sá»‘ notebooks**: 7 labs
- **Tech Stack**: Kafka + Spark + Iceberg + dbt + Great Expectations + Airflow
- **ğŸ“ ThÆ° má»¥c**: `Data_Lakehouse_lab/`

## ğŸ—ºï¸ Learning Path

### Path 1: Real-time Data Processing
```
Kafka Lab â†’ Spark Lab (Streaming) â†’ Airflow Lab â†’ Data Lakehouse Lab
```

### Path 2: Data Transformation & Quality
```
Spark Lab â†’ dbt Lab â†’ Great Expectations Lab â†’ Airflow Lab â†’ Data Lakehouse Lab
```

### Path 3: Data Storage & Lakehouse
```
PyIceberg Lab â†’ Spark Lab â†’ dbt Lab â†’ Data Lakehouse Lab
```

### Path 4: Complete Data Engineer (Recommended)
```
1. Kafka Lab (Ingestion)
2. Spark Lab (Processing)
3. PyIceberg Lab (Storage)
4. dbt Lab (Transformation)
5. Great Expectations Lab (Quality)
6. Airflow Lab (Orchestration)
7. NoSQL Lab (Multi-model)
8. Data Lakehouse Lab (Integration)
```

## ğŸš€ Quick Start

### Prerequisites

- **Docker & Docker Compose**: Táº¥t cáº£ labs sá»­ dá»¥ng Docker
- **Python 3.10+**: Cho Python-based labs
- **Conda/Miniconda**: Cho environment management
- **Git**: Äá»ƒ clone repository
- **Jupyter Notebook**: Cho interactive learning

### Setup

1. **Clone repository:**
```bash
git clone <repository-url>
cd materials
```

2. **Setup environment:**
```bash
# Option 1: Setup táº¥t cáº£ (khÃ´ng khuyáº¿n nghá»‹)
./setup_env.sh

# Option 2: Setup tá»«ng lab riÃªng (khuyáº¿n nghá»‹)
cd Kafka_lab
./setup_kafka_lab.sh
```

3. **Start services:**
```bash
# Má»—i lab cÃ³ docker-compose.yml riÃªng
cd <lab_name>
docker-compose up -d
```

4. **Open Jupyter:**
```bash
conda activate <lab_env>
jupyter notebook
```

## ğŸ“– Lab Details

### Kafka Lab
- **Duration**: ~8-10 hours
- **Difficulty**: Beginner â†’ Intermediate
- **Key Concepts**: Streaming, Consumer groups, Partitioning, Offset management
- **Use Case**: Real-time stock market data processing

### Spark Lab
- **Duration**: ~10-12 hours
- **Difficulty**: Intermediate
- **Key Concepts**: DataFrames, Structured Streaming, MLlib
- **Use Case**: Batch vÃ  streaming data processing

### Airflow Lab
- **Duration**: ~12-15 hours
- **Difficulty**: Intermediate â†’ Advanced
- **Key Concepts**: DAGs, Tasks, Operators, XCom, Scheduling
- **Use Case**: Complete workflow orchestration

### dbt Lab
- **Duration**: ~8-10 hours
- **Difficulty**: Intermediate
- **Key Concepts**: Models, Jinja, Testing, Documentation
- **Use Case**: Data warehouse transformations

### Great Expectations Lab
- **Duration**: ~8-10 hours
- **Difficulty**: Intermediate
- **Key Concepts**: Expectations, Checkpoints, Data Docs
- **Use Case**: Data quality validation

### PyIceberg Lab
- **Duration**: ~10-12 hours
- **Difficulty**: Intermediate â†’ Advanced
- **Key Concepts**: Schema evolution, Partitioning, Time travel
- **Use Case**: Data lakehouse storage

### NoSQL Lab
- **Duration**: ~12-15 hours
- **Difficulty**: Intermediate
- **Key Concepts**: Document, Graph, Key-Value stores, SQL on everything
- **Use Case**: Multi-model database architecture

### Data Lakehouse Lab
- **Duration**: ~15-20 hours
- **Difficulty**: Advanced
- **Key Concepts**: End-to-end integration, Medallion architecture
- **Use Case**: Complete data platform

## ğŸ—ï¸ Repository Structure

```
materials/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt            # Global Python dependencies
â”œâ”€â”€ setup_env.sh                # Global setup script
â”‚
â”œâ”€â”€ Kafka_lab/                  # Kafka streaming lab
â”‚   â”œâ”€â”€ notebooks/              # 5 Jupyter notebooks
â”‚   â”œâ”€â”€ docker-compose.yml      # Kafka services
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ Spark_lab/                  # Spark processing lab
â”‚   â”œâ”€â”€ notebooks/              # Spark notebooks
â”‚   â”œâ”€â”€ code/                   # Spark code examples
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ Airflow_lab/               # Airflow orchestration lab
â”‚   â”œâ”€â”€ notebooks/             # 7 Jupyter notebooks
â”‚   â”œâ”€â”€ dags/                  # Sample DAGs
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ dbt_lab/                   # dbt transformation lab
â”‚   â”œâ”€â”€ notebooks/             # 5 Jupyter notebooks
â”‚   â”œâ”€â”€ models/                # dbt models
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ Great_Expectations_lab/    # GE data quality lab
â”‚   â”œâ”€â”€ notebooks/             # 6 Jupyter notebooks
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ pyiceberg/                 # Iceberg storage lab
â”‚   â”œâ”€â”€ *.ipynb                # 5 Jupyter notebooks
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ NoSQL_lab/                 # NoSQL databases lab
â”‚   â”œâ”€â”€ notebooks/             # 6 Jupyter notebooks
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ Data_Lakehouse_lab/        # Integration lab
    â”œâ”€â”€ notebooks/             # 7 Jupyter notebooks
    â”œâ”€â”€ dags/                  # Complete pipeline DAGs
    â””â”€â”€ README.md
```

## ğŸ”§ Technology Stack

### Core Technologies
- **Apache Kafka**: Real-time data streaming
- **Apache Spark**: Big data processing
- **Apache Airflow**: Workflow orchestration
- **Apache Iceberg**: Data lakehouse format

### Data Tools
- **dbt**: Data transformation
- **Great Expectations**: Data quality
- **Trino**: SQL query engine

### Databases
- **PostgreSQL**: Relational database
- **MongoDB**: Document database
- **Neo4j**: Graph database
- **Redis**: Key-Value store

### Infrastructure
- **Docker & Docker Compose**: Containerization
- **Jupyter Notebooks**: Interactive learning
- **Python 3.10+**: Programming language

## ğŸ“ Best Practices

### Lab Workflow
1. **Read README**: Äá»c ká»¹ README cá»§a tá»«ng lab trÆ°á»›c khi báº¯t Ä‘áº§u
2. **Setup Environment**: Cháº¡y setup script vÃ  start services
3. **Follow Notebooks**: LÃ m theo thá»© tá»± notebooks
4. **Experiment**: Thá»­ nghiá»‡m vÃ  customize code
5. **Document**: Ghi chÃº láº¡i nhá»¯ng gÃ¬ há»c Ä‘Æ°á»£c

### Code Practices
- âœ… Sá»­ dá»¥ng version control (Git)
- âœ… Comment code rÃµ rÃ ng
- âœ… Follow PEP 8 (Python style guide)
- âœ… Test code trÆ°á»›c khi submit
- âœ… Document findings vÃ  issues

## ğŸ› Troubleshooting

### Common Issues

1. **Port Conflicts**:
   - Check ports Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng: `lsof -i :<port>`
   - Stop conflicting services hoáº·c change ports trong docker-compose.yml

2. **Docker Issues**:
   - Ensure Docker daemon Ä‘ang cháº¡y
   - Check disk space: `docker system df`
   - Clean up: `docker system prune`

3. **Environment Issues**:
   - Activate correct conda environment
   - Check Python version: `python --version`
   - Reinstall dependencies: `pip install -r requirements.txt`

4. **Connection Issues**:
   - Verify services Ä‘ang cháº¡y: `docker-compose ps`
   - Check logs: `docker-compose logs <service>`
   - Wait for services to be ready (cÃ³ thá»ƒ máº¥t vÃ i phÃºt)

## ğŸ“š Additional Resources

### Documentation
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [dbt Documentation](https://docs.getdbt.com/)
- [Great Expectations Documentation](https://docs.greatexpectations.io/)
- [Apache Iceberg Documentation](https://iceberg.apache.org/docs/)

### Learning Resources
- Má»—i lab cÃ³ README.md riÃªng vá»›i detailed instructions
- Notebooks cÃ³ comments vÃ  explanations chi tiáº¿t
- Sample code vÃ  use cases thá»±c táº¿

## ğŸ¤ Contributing

Náº¿u báº¡n phÃ¡t hiá»‡n lá»—i hoáº·c muá»‘n cáº£i thiá»‡n labs:

1. Create an issue vá»›i mÃ´ táº£ chi tiáº¿t
2. Fork repository vÃ  táº¡o branch má»›i
3. Make changes vÃ  test thoroughly
4. Submit pull request vá»›i description rÃµ rÃ ng

## ğŸ“„ License

TÃ i liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch giÃ¡o dá»¥c trong khÃ³a há»c Big Data Engineering.

## ğŸ‘¥ Authors

- **Course Instructor**: [Your Name]
- **Institution**: SoICT, HUST

## ğŸ™ Acknowledgments

- Apache Software Foundation cho cÃ¡c open-source projects
- Community contributors cho documentation vÃ  examples
- Students cho feedback vÃ  improvements

---

## ğŸ“ Support

Náº¿u cÃ³ cÃ¢u há»i hoáº·c cáº§n há»— trá»£:
- Check lab-specific README.md
- Review troubleshooting section
- Contact instructor hoáº·c TA

---

**Happy Learning! ğŸš€**

*Last Updated: 2024*

